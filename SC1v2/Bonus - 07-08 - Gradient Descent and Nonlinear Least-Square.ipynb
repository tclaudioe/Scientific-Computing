{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"http://sct.inf.utfsm.cl/wp-content/uploads/2020/04/logo_di.png\" style=\"width:60%\">\n",
    "    <h1> INF285 - Computación Científica </h1>\n",
    "    <h2> Gradient Descent and Nonlinear Least-Square </h2>\n",
    "    <h2> <a href=\"#acknowledgements\"> [S]cientific [C]omputing [T]eam </a> </h2>\n",
    "    <h2> Version: 1.00</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='toc' />\n",
    "\n",
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "* [Weighted least-square](#wLeastSquare)\n",
    "    * [Example in explanation](#exampleExplanation)\n",
    "    * [Extension of \"Initial Example\" in jupyter notebook \"07_08_Least_Squares\"](#extensionInitialExample)\n",
    "* [Acknowledgements](#acknowledgements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as spla\n",
    "%matplotlib inline\n",
    "# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n",
    "from sklearn import datasets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, RadioButtons\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 20\n",
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "M=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='intro' />\n",
    "\n",
    "## Introduction\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "This jupyter notebook presents the algorithm of Gradient Descent applied to non-linear least-square problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='GradientDenscent' />\n",
    "\n",
    "## Gradient Descent\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "The algorithm of Gradient Descent is used in Optimization, in particular, in problems when we want to minimize a function (or equivalently in maximization problem by changing the sign of the function).\n",
    "This algorithm considers a function $f(\\mathbf{x}):\\mathbb{R}^n \\rightarrow \\mathbb{R}$, which has at least a local minimum near the point $\\mathbf{x}_0$.\n",
    "The algorithm considers that we have access to the gradient of $f(\\mathbf{x})$, i.e. $\\nabla f(\\mathbf{x})$, which indicates the direction of fastest increase of $f(\\mathbf{x})$ at the point $\\mathbf{x}$, or equivalently, $-\\nabla f(\\mathbf{x})$ is teh direction of fastest decrease.\n",
    "Thus, the algorithm is the following,\n",
    "- Select an initial guess, say $\\mathbf{x}_0$\n",
    "- Compute the direction of fastest decrease: $\\mathbf{d}_0=-\\nabla f(\\mathbf{x}_0)$\n",
    "- Update the approximation $\\mathbf{x}_1=\\mathbf{x}_0+\\alpha\\,\\mathbf{d}_0$\n",
    "- Iterate until certain threshold is achieved.\n",
    "where $\\alpha$ is a scaling factor for the Gradient Descent step.\n",
    "The coefficient $\\alpha$ could also depend on on the iteration number, such that it adapts based on the iterations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='GradientDenscent1D' />\n",
    "\n",
    "## Gradient Descent in 1D\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "To primary explain the algorithm, considere the following 1D example:\n",
    "$$\n",
    "f(x) = (x - 2)\\,\\sin(2\\,x) + x^2.\n",
    "$$\n",
    "We will first plot the function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAHtCAYAAACzhc/9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABOH0lEQVR4nO3dd3Rc1aE18H1mRhr13rvk3uQiueBuTDUGTO8EcGIIvISEl5eE93gpX0h56YQEEggJxQEDodp0cANXyb1bkq3eex1pyvn+kIwtI9sqM3Pm3rt/a3klSPLMzkXR1rn3FCGlBBEREXmWSXUAIiIiI2DhEhEReQELl4iIyAtYuERERF7AwiUiIvICFi4REZEXWDz54jExMTIjI8Ntr9fR0YHg4GC3vZ7W8Xr0x+txGq9Ff7we/fF6nObua7Fr1656KWXsQJ/zaOFmZGQgPz/fba+3ceNGLF682G2vp3W8Hv3xepzGa9Efr0d/vB6nuftaCCFKzvU53lImIiLyAhYuERGRF7BwiYiIvICFS0RE5AUsXCIiIi/w6CzlC2ltbUVtbS3sdvugvj48PBxHjhzxcCrfEhwcjJSUFJhM/N2IiEjLlBVua2srampqkJycjMDAQAghLvh32traEBoa6oV0vsHlcqGiogL19fWIi4tTHYeIiEZA2bCptrYWycnJCAoKGlTZGpHJZEJ8fDxaWlpURyEiohFSVrh2ux2BgYGq3l4z/Pz84HA4VMcgIqIRUvpgkCPbC+M1IiLSB87EISIi8gIWLhERkRewcImIiLyAhTsCzz77LLKysmCxWHD//fcjPj4eRUVFg/77N954I37/+997MCEREfkKFu4wHT16FN/85jfxu9/9DmVlZQgKCsKyZcswatSoQb/Gj3/8Yzz++ONc9kNEZAAs3GF69913MXnyZFx33XUIDw/H888/j5UrVw7pNaZMmYKsrCysXr3aQymJiMhXsHCHYezYsfjBD36Affv2QQiB4OBgmEwmzJs3r9/Xvf7667BarSgpOX0e8cMPP4xRo0ahpqYGAHDNNdfglVde8Wp+IiICmjt70OOUXns/pXspn+2naw/hcGXrOT/vdDphNpvd+p4Tk8Lw46snDenvfPHFF1iwYAHuvvturFy5Eo8++igqKiq+smb2xhtvxP/93//h8ccfx7PPPovf/va3eOWVV7BlyxbEx8cDAGbNmoXHH38cXV1d3AiEiMiL/rKhEC9t7cTBxS5YzJ4ff/pU4WpFWFgYTpw4gXnz5iEhIQFNTU1ITEz8ytcJIfCLX/wCV111FUaNGoWf//znWL9+PcaMGfPl1yQlJcFut6OysnJIz3+JiGhkdpc2IyXU5JWyBXyscC800vSVwwsOHjwIh8OBadOmAQC6urq+HLGe7bLLLsPMmTPx2GOPYe3atZg5c2a/z58a1XZ1dXk0MxERndbjcOFARQuWpHjvySqf4Q7D3r17kZ6ejoiICABATEwMmpqaBvza9evXY9++fZBSDljKjY2NAIDY2FiP5SUiov4OV7Wix+HC6Aj3PqY8HxbuMOzdu/fL0S0ATJ8+HYcPH/7K1+3btw/XX389nnzySaxYsQKPPvroV77m4MGDSEpKOucImYiI3G93Se8gaXQER7g+7ezCvfzyy3HkyBE0NDR8+bGSkhIsW7YMjzzyCO677z789Kc/xSeffIKNGzf2e63PP/8cV1xxhZeSExERAOwpa0ZSeAAiA1i4PktKif379/cr3ClTpmDWrFlYs2YNgN7bxFdccQWWL1+OH/3oRwCAyZMn46abbuo3yrXZbHjrrbfwjW98w6v/G4iIjG53SROmp0V69T19atKUFggh0Nr61aVLP/7xj/Hwww/jgQceQFRUFI4cOfKVr3n11Vf7/fNzzz2H2bNnY86cOR7LS0RE/dW22lDR3IV752UAznMvRXU3jnDd5IorrsBDDz2E8vLyQf8dPz8/PPnkkx5MRUREZ9td2vv8dkY6R7ia9e1vf3tIX79q1SoPJSEionPZU9oMf7MJk5LCsO2E996XI1wiIjKU3aVNmJQcBqvFe0uCABYuEREZSI/Dhf3lLZjh5QlTgOLCldJ7m0ZrFa8REZH7HKpsQbfDhVwvP78FFBaun58ftzMcBLvdDouFj9qJiNwhv7h3wlROhoEKNy4uDhUVFejs7OQo7hxcLhdqamoQHh6uOgoRkS7klzQiPToIcaEBXn9vZUOnsLAwAEBlZSXsdvug/o7NZkNAgPcvkkrBwcGIiYlRHYOISPOklMgvbsKicWr2rld6rzIsLOzL4h2MjRs3Yvr06R5MREREelXc0ImGjh7kpkcpeX/OUiYiIkPIL+49nW2mgue3AAuXiIgMIr+4CeGBfhgVG6Lk/Vm4RERkCPkljchNj4TJJJS8PwuXiIh0r7GjB0V1HUqWA53CwiUiIt3b1XfgvKoJUwALl4iIDCC/uBH+ZhOyU9Tta8DCJSIi3csvacLk5DAE+Hn3wIIzsXCJiEjXbHYnDpS3YGaGutvJAAuXiIh07kBFC3qcLuQoOLDgTBcsXCGEWQjxMyHESSGEre8/HxdCcEd9IiLyeXl9G16oLtzBlOYPADwE4GsADgDIBvACgG4AP/NcNCIiopHbVdyErNhgRIdYleYYTOHOBbBWSrm275+LhRDvApjtuVhEREQj53JJ5Jc04fJJ8aqjDOoZ7hcAlgghxgOAEGIigIsBvO/JYERERCNVUNuOli47chVPmAIAcaGzaIUQAsDjAB4F4ETvqPjnUsrHzvH1qwCsAoD4+PicNWvWuC1se3s7QkLU7IHpi3g9+uP1OI3Xoj9ej/6MdD0+LbFj9ZEe/HphIOKCvjrGdPe1WLJkyS4pZe6An5RSnvcPgFsBlPX95xQAdwFoBLDyQn83JydHutOGDRvc+npax+vRH6/HabwW/fF69Gek6/Hg6l1yzi8+lS6Xa8DPu/taAMiX5+jEwTzD/Q2A30opTw1VDwgh0tE74n1uRL8KEBEReYiUEjtONmD+6Bj03qxVazDPcIPQeyv5TM5B/l0iIiIliuo6UN/egzlZ0aqjABjcLOW1AH4ohDgJ4BCA6QAeAfCiJ4MRERGNxI6TDQCA2Roq3G+hd73tUwDiAFQBeBbA//NgLiIiohHZcaIRcaFWZEQHqY4CYBCFK6VsA/Cdvj9EREQ+79Tz29lZ0T7x/Bbgc1giItKhkoZO1LR2Y3am+vW3p7BwiYhId049v52TxcIlIiLymB0nGhET4o9Rsb6zwQcLl4iIdEVKie0nGjArM8pnnt8CLFwiItKZ8qYuVLbYMDvTN5YDncLCJSIiXdl+4tT6W995fguwcImISGd2nGxERJAfxsaFqo7SDwuXiIh0Q0qJbUUNmJMZDZPJd57fAhoq3C8K6vGHXTa02eyqoxARkY8qbexERXMX5o32ree3gIYKt7GzB/vqnKhqsamOQkREPmpLYe/z24tGxShO8lWaKdyk8AAAYOESEdE5bSmqR3yYFaNig1VH+QrNFG7CqcJt7lKchIiIfJHL1fv8dt4o3zj/9myaKdz4sAAIcIRLREQDO1rdhsaOHswd7Xu3kwENFa6f2YRwq0BVC0e4RET0VVuL6gHAJydMARoqXACIChAc4RIR0YC2FjUgKyYYieGBqqMMiIVLRESaZ3e6sONEA+b66OgW0FjhRgYIVDV3QUqpOgoREfmQ/eXN6OhxYq4PLgc6RVOFGxVgQkePE23dDtVRiIjIh2wpbIAQwEVZHOG6RVRA7zTvqmbeViYiotO2FNZjYmIYIoP9VUc5J20WLmcqExFRn64eJ/aUNmOejy4HOkWjhcsRLhER9corbkSP04W5o3z3djKgscKNsAqYBHebIiKi0z4vqIO/2YRZmb51/u3ZNFW4ZpNAXGgAR7hERPSlzcfrkZsRiSB/i+oo56WpwgV691Rm4RIREQBUt9hwrKYNC8fGqo5yQZor3KSIAE6aIiIiAMDmgjoAwCIWrvslhAWiqsXGzS+IiAibj9chLtSK8QmhqqNckOYKNykiAJ09TrTauPkFEZGROV0SXxTWY8GYWJ88ju9smivcU5tS87YyEZGx7S9vRnOnHQvH+vb621M0V7inD6LnxCkiIiPbfLweQgALxvj+81tAg4WbFNFXuJypTERkaJsL6pCdHI4oH97O8UyaK9zYEGvv5he8pUxEZFgtXXbsLWvWxHKgUzRXuBazCfFhXItLRGRkWwvr4XRJFq6n9W5+wREuEZFRbS6oQ6jVgmmpEaqjDJomCzcpPJAjXCIig5JSYtOxOswdHQ0/s3ZqTDtJz5AYHoCqZm5+QURkRAW17ahssWHR2DjVUYZEk4WbEB6ALrsTLV121VGIiMjLPjtSCwC4eDwL1+OSIk5tfsHbykRERrP+aA0mJYV9uS+DVmiycL/c/IITp4iIDKWpowe7SpqwVGOjW0CjhZsUzhEuEZERbTpeB5cELp4QrzrKkGmycGNDrTCbBLd3JCIymM+O1iImxB/ZyeGqowyZJgvXbBKID7VyhEtEZCB2pwubjtViybg4mEy+fzrQ2TRZuACQGBHIZ7hERAayq6QJrTYHlk7Q3vNbQMOF27vbFEe4RERGsf5oLfzMAvM1cjrQ2TRbuEl92zty8wsiImP47EgN5mRFI8RqUR1lWDRbuAnhgbDZXWju5OYXRER6V9LQgaK6Ds1tdnEmzRZuUjjPxSUiMor1R7W5u9SZNFu43PyCiMg4Pj1Sg1GxwUiPDlYdZdg0W7jc3pGIyBiaO3uw/UQjLpuUoDrKiGi2cGNCrLCYBEe4REQ699mRWjhdEpezcNUwmwTiwwJQyd2miIh07aND1UgMD9Dk7lJn0mzhAkByRCAqmjnCJSLSq84eBzYX1OGyifGa3F3qTJou3KSIAFSycImIdGvz8TrY7C7N304GNF64yZGBqG6xweni5hdERHr00aEaRAT5YVZmlOooI6bpwk2KCITDJVHbxue4RER6Y3e68NmRGiwdHw+LWdN1BUAHhQuAt5WJiHRo+4kGtNocuHyS9s6+HYimCzelr3ArOFOZiEh3PjpUjUA/MxaO1eZhBWfTdOEmnircJo5wiYj0xOWS+PhQDRaNjUWAn1l1HLfQdOGGWC0ID/TjLWUiIp3ZW96M2rZuXD5ZH7eTAY0XLtC7FpeFS0SkL+/vr4KfWeDi8Sxcn5HEzS+IiHTF5ZJ470AVFo6JRXign+o4bqP5wk2OCGDhEhHpyO7SJlS12LB8aqLqKG6l/cKNDESbzYFWGw+iJyLSg3X7q+BvMeGSCfq5nQzooHC/PKaPS4OIiDTP6ZJ4/0AVFo+NRWiAfm4nAzoq3IrmTsVJiIhopPKKG1Hb1o3lU5NUR3E7zRduMje/ICLSjff2VyHAz4Sl4+NUR3E7zRdubIgVfmbBpUFERBrncLrwwcEqXDw+DsFWi+o4bqf5wjWZBBLDA7nbFBGRxu042Yj69h4sz9bf7WRAB4UL8FxcIiI9WLe/CkH+ZiwZp7/byYBOCjc5IoiFS0SkYXanCx8erMLSCfEI9NfH3sln00nhBqC61Qa706U6ChERDcPm43Vo6rTjGh3OTj5lUIUrhEgUQrwghKgTQtiEEIeFEIs8HW6wkiIC4ZJATStnKhMRadGbeyoQGeSHRTo5im8gFyxcIUQEgC0ABICrAEwA8C0AtR5NNgTJkacOomfhEhFpTavNjk8P1+DqqUnwt+jixuuABjPv+vsAqqSUd5/xsZMeyjMs/Te/iFIbhoiIhuTDA9XodriwYnqy6igeNZhfJVYA2CGEeFUIUSuE2CuE+A8hhPBwtkFLCucIl4hIq97aU4GM6CBMT41QHcWjhJTy/F8gxKkW+wOA1wBMA/AkgB9KKf88wNevArAKAOLj43PWrFnjtrDt7e0ICQkZ8HPfWt+BnHgL7plkddv7+brzXQ8j4vU4jdeiP16P/nzpejR0ufC9TV24drQfVoz29/r7u/taLFmyZJeUMnfAT0opz/sHQA+ArWd97BcAjlzo7+bk5Eh32rBhwzk/t/xPn8u7n9vh1vfzdee7HkbE63Ear0V/vB79+dL1eGpDoUz/wTpZXN+u5P3dfS0A5MtzdOJgbilXATh81seOAEgb7m8AnsDNL4iItEVKibf2lGNGWgTSo4NVx/G4wRTuFgDjzvrYWAAl7o8zfEkRgahs7jo1AiciIh93uKoVx2vacd2MFNVRvGIwhfsHAHOEEP8jhBgthLgJwLcB/MWz0YYmOSIQHT1OtHTxIHoiIi14a3cF/MwCy6ckqo7iFRcsXCllHnpnKt8M4CCAnwP4XwBPeTTZEJ0+po+3lYmIfF2Pw4W39lTg4vFxiAz2/mQpFQZ1/pGU8j0A73k4y4icWotb2WzDpKRwxWmIiOh81h+tRUNHD26Zmao6itfoZkuP07tNcYRLROTrXssvQ1yoFQvH6Hcrx7PppnCjg/3hbzHxljIRkY+rbrFh47Fa3JiTAotZNzV0Qbr5XyqEQEoED6InIvJ1b+wuh0sCN+ca53YyoKPCBXpvK5c3daqOQURE5+BySbyWX4bZmVHIiNH/2tsz6apwUyKDUM4RLhGRz9pZ3IiShk5DTZY6RWeFG4iGjh509jhURyEiogG8lleGUKsFV042xtrbM+mqcFOjggCAo1wiIh/UarPj/YNVuHpaEgL9zarjeJ2uCjelb2kQn+MSEfmed/ZUwGZ34RaDTZY6RaeFyxEuEZEvkVJi9fZSTE4OQ3aKMTcn0lXhxoZYYbWYUNbIES4RkS/JL2nCsZo23Dk7HUII1XGU0FXhCiGQEhnIES4RkY9Zvb0EoQEWXDMtSXUUZXRVuACXBhER+ZqG9m58cKAaN8xIQZD/oLbw1yUdFm4gyjhpiojIZ7yWX44epwt3zE5THUUp3RVualQQmjvtaLPxXFwiItVcLomXd5ZgdmYUxsSHqo6jlO4K99RMZR5iQESk3uaCOpQ1duGOOemqoyinw8Lt3fyirJGFS0Sk2urtpYgJ8ccVkxJUR1FOd4Wbys0viIh8QlljJ9YfrcHNuanwt+iuboZMd1cgKtgfgX5mzlQmIlLsha3FEELgrot4OxnQYeGeWovLzS+IiNTp6Hbg1fwyLJuSiMTwQNVxfILuChfonanMES4RkTpv7C5Hm82Be+dlqI7iM3RZuCk8iJ6ISBmXS+KfW4oxLTUCM9IiVcfxGbot3FabAy1dXItLRORtm47X4WR9B0e3Z9Fl4aZGnjoXl6NcIiJv+8eWk4gPs2LZFOMdMn8+uizclEgeRE9EpEJBTRs+L6jH3RdlwM+sy4oZNl1ejVO7TXGmMhGRd/1zazGsFhNum2XsfZMHosvCjQjyQ4jVwhEuEZEXNXb04M3d5bhuejKigv1Vx/E5uixcnotLROR9L24rhs3uwsr5maqj+CRdFi7ApUFERN7U1ePEC1uLccmEOMOfCnQuOi7c3s0vpJSqoxAR6d7ru8rQ1GnH/YtGqY7is3RcuIFo7+ZaXCIiT3M4XXj28xOYkRaB3HRudHEuOi5cHtNHROQNHxysRlljF+5fNApCCNVxfJZuCzc1qm9pEJ/jEhF5jJQSf9tchKzYYFw6IV51HJ+m28JNi+od4ZZyLS4RkcdsKWzAwYpW3L8wCyYTR7fno9vCDQ3wQ1SwP0oaWLhERJ7yt81FiA21YsX0ZNVRfJ5uCxfoPaaPu00REXnGwYoWfF5Qj/vmZcJqMauO4/N0XbjpUUEoaexQHYOISJee3lSEEKsFt8/mNo6DoevCTYsKQmWzDXanS3UUIiJdKaxtw/sHqnD3RekID/RTHUcT9F240UFwuiQqm7k0iIjInZ7aUIQAi5nbOA6Bvgu3b6YyJ04REblPSUMH3tlXiTtmpyE6xKo6jmbounDTo7k0iIjI3Z7eWASzSWDVwizVUTRF14UbHxoAf4uJhUtE5CYVzV14Y3c5bp2ZiriwANVxNEXXhWsyCaRGBqKUt5SJiNzib5uKAICHFAyDrgsX6H2OW8IRLhHRiNW22rAmrww3zEhBckSg6jiao/vCTY8ORmlDB4/pIyIaoWc2n4DTJfHNxRzdDofuCzctKggdPU40dvSojkJEpFkN7d34145SXDs1CenRwarjaJIhChcAbysTEY3Ac1+chM3hxINLOLodLt0X7qmlQdxTmYhoeBo7evDC1mIsm5KI0XGhquNolu4LN5WbXxARjcjfNheh0+7Ed5aOUR1F03RfuAF+ZsSHWbkWl4hoGOrauvHi1hJcOzUJY+I5uh0J3Rcu0Pscl2txiYiG7umNRehxuvDwJWNVR9E8gxRuMEe4RERDVN1iw+odJbhuejIyYzgzeaQMUrhBqG61wWZ3qo5CRKQZf9lQCJdL4mE+u3ULQxQuZyoTEQ1NRXMX1uSV4qbc1C8nn9LIGKJw03hqEBHRkPx5fQEEBL518WjVUXTDGIXLpUFERINW2tCJ1/PLcdusVCRxz2S3MUThRgf7I9jfzBEuEdEgPPFZAcwmgYeWcHTrToYoXCEE0qODcbK+Q3UUIiKfVlTXjrf2lOOuOek879bNDFG4AJAZG4ziBhYuEdH5PPFpAawWMx7giUBuZ5zCjQ5GeVMX7E6X6ihERD7pWHUb1u6vxNfmZiAmxKo6ju4YpnAzYoLhdEkuDSIiOocnPjuOYH8L7l+YpTqKLhmmcDNjemcq87YyEdFXHapswfsHqnHfvAxEBvurjqNLhincjL4Dk0/Wc4RLRHS2P3xSgLAAC1Yu4OjWUwxTuFHB/ggNsOBkfbvqKEREPmVfWTM+PVKDbyzIQnign+o4umWYwhVCICsmGMUc4RIR9fP7T44jIsgP987PVB1F1wxTuEDvxCmuxSUiOm1XSSM2Ha/D/QtHIcRqUR1H14xVuNHBqGzp4qlBRER9fvfxccSE+ONrc9NVR9E9QxVuZkwwpOSpQUREALCtqAFbixrwwKJRCPLn6NbTDFW4GTGnZirztjIRGZuUEn/45Djiw6y4cw5Ht95gqMLN7FsaxLW4RGR0XxTWY2dxIx5aMhoBfmbVcQzBUIUbHuSHqGB/rsUlIkOTUuJ3Hx9HUngAbpmZqjqOYQy5cIUQ/y2EkEKIP3sikKdlRAehmLeUicjA9tU5sbesGd9aOgZWC0e33jKkwhVCzAHwDQD7PRPH87g0iIiMTEqJtwrtSI0KxI05KarjGMqgC1cIEQ7gXwBWAmjyWCIPy4wORnWrDV09XBpERMbz8eEalLS68O2Lx8DPbKinisoN5Wo/A+DfUsr1ngrjDadmKnPiFBEZjcvVOzM5IUjguunJquMYjpBSXviLhPgGgAcAXCSl7BFCbARwUEr5HwN87SoAqwAgPj4+Z82aNW4L297ejpCQkBG9RnGLEz/ZZsND06yYmaDtdWfuuB56wutxGq9Ff7wevXZWOfDUvm58bazEkixeD8D93xtLlizZJaXMHehzF2wcIcQ4AL8AsEBK2XOhr5dSPoPe0TByc3Pl4sWLh5b2PDZu3IiRvl57twM/2fYRghMysHjxaPcEU8Qd10NPeD1O47Xoj9cDcLokHv/jZoyJ88OiTJfhr8cp3vzeGMwt5YsAxAA4KIRwCCEcABYBeLDvn60eTehmIVYLYkOtnKlMRIaydl8lCmvb8Z1LxsIkhOo4hjSYwn0bwBQA0874kw9gTd9/v+Co19dkRvPUICIyDofThSc+K8D4hFBcOTlBdRzDuuAtZSllM4DmMz8mhOgA0CilPOiZWJ6VFRuMT4/UqI5BROQVb+6pwMn6DjxzVw5MJo5uVTHknPBRsSGob+9Bc6fmBudERENid7rwp88KMCU5HJdOjFcdx9CGVbhSysUDzVDWilFxvUuDiur4HJeI9O31/HKUN3XhkUvHQvDZrVKGHeECQFFdu+IkRESe0+1w4s/rCzA9LQKLx8WqjmN4hizclMgg+JtNLFwi0rU1O8tQ2WLDf146jqNbH2DIwjWbBDJjglFUy1vKRKRPNrsTf9lQiFmZUZg3Olp1HMIgZinr1ai4YBypalMdg4aovr0bWwrrUVDTjppWG0xCIDrEH+MSQoHuC++aRmQUL+8oRW1bN/5023SObn2EcQs3NgQfHapBt8PJ46l8nJQSnx2pxT+2nMTWogYAvXcpYkL8ISXQ2NEDh0tCAHitbDu+sSALi8bG8ocMGZbN7sRfNxVhTlYU5mRxdOsrDF24TpdEaUMnxsSHqo5D53CosgU/fucQ8kuakBgegO9cMgZLx8djfGLolyed9DhcOF7Thmff34GddR245595mJkRiZ9fNwVj+e+WDOi1/DLUtnXjj7dOUx2FzmDowgV6ZyqzcH2PyyXx7Ocn8JuPjiE80A+/vH4KbsxJGfA4MX+LCZOTw3HdGH/85t6F+Peucvz6o6O46k+f49ErJ+DeeRkc7ZJhdDuceHpjEWZmROIijm59imELNyuWa3F9lc3uxHfW7MWHh6qxbEoCfnldNsKD/Ab1d/0tJtw+Ow2XT4rHD944gP+37jD2lTfj1zdm89EBGcLr+eWoarHhNzdO5S+aPsawhRtstSAxPABFtVwa5EuaO3vwjRfzkV/ShMeumoCV8zOH9UMjOsSKZ+7KwdObivCbj46hsaMHf70zB8FWw37LkwH0OFx4emMRZqRFcGayDzLksqBTRsWGcC2uD2mz2XHXczuxr6wFT942HV9fkDWi39BNJoGHlozGr2/MxpbCenzjxXzY7E43JibyLW/uLkdFcxe+vXQMR7c+yOCFG4yiug5IyeUkqnX1OLHyhXwcqWrF03fOwPLsJLe99s25qfjdzVOxtagB31mzF04X/32T/tidLvx5QyGmpoRj0VjuKuWLDF24o+NC0N7tQG1bt+oohuZySXz31b3IK27EH26ZhqUT3L/B+nXTU/Cj5RPx4aFq/GzdYbe/PpFqb+2pQHlTFx6+hKNbX2Xowv1ypjKf4yr15PpCfHioGv+zbAKunuq+ke3Z7pufiZXzM/H81mK8savcY+9D5G0Opwt/2VCIyclhWDIuTnUcOgdjF24cDzFQ7eND1fjDp8dx/YxkrJyf6fH3e/TK8ZiTFYX/fusADla0ePz9iLzh3X2VKGnoxLcv5ujWlxm6cONCrQixWlDIEa4SVS1d+K9/78eU5HD84ropXvlBYTGb8OfbZyAyyB/ffmUPOnscHn9PIk9yuiT+vL4QExLDeN6tjzN04QohMCouBAUsXK9zuSQeeXVf7+HYt01HgJ/31sjGhFjx+5un4kR9B375/lGvvS+RJ6zbX4kT9R349sWjObr1cYYuXAAYGxeC4zUsXG975vMT2HaiAT+5ehIyY4K9/v5zR8fg6/Mz8dL2Emw4Vuv19ydyByklnt5YhNFxIbh8UoLqOHQBLNz4UNS3d6Oxo0d1FMMoqGnD7z4+hisnJ+Cm3BRlOb53+TiMiQvBY28d5K1l0qT1R2txtLoN31w0CiYTR7e+joWb0LuP8vEaHtXnDS6XxKNvHkCw1YLHV0xWegsswM+MX1w/BRXNXXji0wJlOYiGQ0qJpzYWITkiENdM89zsfnIfFm5870zlAhauV7ySV4r8kib8z7IJiA6xqo6DmRlRuCU3FX//4iSOVreqjkM0aDtPNmJXSRNWLcwa8FAP8j2G/7eUEBaAUKuFz3G9oLbVhl99cBQXZUXjxhx1t5LP9sMrxyMswIL/fvMAXNyFijTi6U1FiA72x825qaqj0CAZvnCFEBibEIpjHOF63K8+OIpuuws/v07treSzRQb749ErJ2B3aTPW7q9UHYfogg5VtmDjsTrcNz8Tgf48BUsrDF+4QO9t5YKaNu6p7EH7yprx5p4KrFyQiay+Hb58yQ05KZiQGIZff3iMBxyQz3t6YxFCrBbcOSdddRQaAhYugDFxoWjqtKO+nTOVPUFKiZ+tO4yYEH88uHiU6jgDMpsE/mfZBFQ0d+HFbcWq4xCdU3F9B94/UIU75qQhPHBw50STb2DhAhjHmcoe9f6BauSXNOE/LxuH0ADf/QExf0wMFo+LxZPrC9HEZWLko/62uQgWs8krW6GSe7FwAYzpm6nMwnU/m92JX35wBOMTQjUxuePRKyego9uBpzYWqo5C9BU1rTa8sasCN+WkIC40QHUcGiIWLoDYECsigvw4U9kDVm8vQXlTFx67aiLMGliYPy4hFCumJeOl7SWobbOpjkPUz3NfnITD5cL9C33z0QydHwsXfTOV40M5wnWzjm4Hnt5YhPmjYzB/TIzqOIP2raVjYHdK/G3TCdVRiL7UarPj5R2luCo7CWnRQarj0DCwcPuMjQ/Bcc5UdqvntxajoaMHj1w2VnWUIcmMCcaKaclYvb0Eta0c5ZJvWLOzFO3dDqxakKU6Cg0TC7fP2PhQtNkcqGntVh1FF1q67PjbpiIsHR+HGWmRquMM2beXjobDJfH0piLVUYhgd7rwzy3FmJMVhSkp4arj0DCxcPuMje+dqcwNMNzjuS9OotXmwHcv1dbo9pT06GBcPz0ZL+8oRX07fwkjtd7bX4WqFhtWLeToVstYuH1OFe7xahbuSDV19OAfX5zEsikJmJys3d/GH1g8Cj1OF17cWqw6ChmYlBLPbD6B0XEhWDw2TnUcGgEWbp+oYH/EhVpxhBvYj9jzW4vR3u3Aw0u1Obo9ZVRsCC6dEI8XtpWgo5vH95Ea24oacLiqFV+fn8kj+DSOhXuGCYlhOFLFEe5ItHc78PzWYlw2Mf7LDUW07IHFo9DSZcereWWqo5BBPfP5CcSE+GPF9GTVUWiEWLhnmJgUhsLaNvQ4XKqjaNbLO0rQ0mXHg0tGq47iFjPSIjErIwrPfXESdie/L8i7jte0YeOxOnztogwE+PGQAq1j4Z5hQmIY7E6JwlpugDEcNrsTz35+EvNHx2BaaoTqOG7zwOIsVDR3YR1PEiIv+/vnJxDgZ+IhBTrBwj3DxMTeW6BHqvgcdzj+vascdW3deHCJvnbBWTw2DmPjQ/DM5pNcp01eU9tmw9t7KnFTTioig/1VxyE3YOGeITMmBAF+Jhxm4Q6Zw+nCXzcVYXpaBC7KilYdx61MJoF752XiSFUr8oqbVMchg3hxawnsLhcPKdARFu4ZzCaBcfGhHOEOw7r9VShv6sJDi0f71OHy7rJiWjLCAix4gUuEyAu6epxYvaMEl02MR0ZMsOo45CYs3LNMTArD4apW3jocAikl/v5F7zrBi8frc51goL8Zt8xMxYeHqlHV0qU6DuncW3sq0Nxpx8r53OhCT1i4Z5mQGIbmTjuquYfuoO082YiDFa24b56+1wneNScDLinxr+2lqqOQjkkp8fzWk5iUFIaZGdrbFpXOjYV7lgmJYQA4cWoo/v7FSUQG+eH6GfpeJ5gWHYSl4+Pwys5S2OxO1XFIp7YWNeB4TTvumZuhy8czRsbCPcv4vs0aDleycAejuL4Dnx6pwZ1z0g2xTvBrczPQ0NGD9/ZXqY5COvXPLcWIDvbH1VOTVEchN2PhniU0wA9pUUHccWqQ/rnlJPxMJtx1kTHWCc4fHYOs2GC8sK1YdRTSoZKGDnx2tAa3z04zxC+wRsPCHcDExDAuDRqElk47Xssvx9VTkxAXGqA6jlcIIXD3nHTsL2/BgfIW1XFIZ17cVgKzENzoQqdYuAOYkBiG4oYOblh/Aa/klaLL7jTcOsHrZqTAajHhlTxOniL3ae924LW8Miybkoj4MGP8Ams0LNwBTEgMhZTAUR7Vd052pwvPbynG3FHRmJgUpjqOV4UH+uGq7ES8u7eSv5SR27yxqxxt3Q7cOy9DdRTyEBbuACb1neF6qJK3DM/l/QNVqG614esLjDW6PeX2WWlo73Zw8hS5hcsl8cLWYkxNjcD0NC4F0isW7gCSwgMQHezPZ3Tn8dK2EmREBxn2QOyc9EiMjgvByzt5W5lGblNBHU7Ud+A+jm51jYU7ACEEpqSE40AFC3cghytbkV/ShDvnpOt6o4vzEULg1pmp2FvWjKPVnGBHI/P8lmLEhVpx5eRE1VHIg1i45zAlORzHa9rQ1cMNDs720vYSBPiZcFNOquooSt0wIwX+ZhPW7OTh9DR8RXXt2HS8DnfOSYe/hT+S9Yz/ds9hSnI4XBJcHnSWVpsdb++pwDVTkxAe5Kc6jlKRwf64YnIC3txdzp2naNhWby+Bn1ngtllpqqOQh7FwzyE7JQIAcKC8WWkOX/PmrnJ02Z24a06G6ig+4dZZqWi1OfDhwWrVUUiDOnsc+Peuclw5ORGxoVbVccjDWLjnEB9mRWyoFfv5HPdLUkq8tL0EU1MjMCUlXHUcnzAnMxopkYF4Y3e56iikQWv3VaLN5jDMTm1Gx8I9ByEEspPDOVP5DNuKGlBU14G7uQvOl0wmgetnpOCLwnoe20dDIqXEi9tKMC4+FLnpXApkBCzc85iSEo7CunZubtDnpe0liAjq3fSBTrthRjKk7D3DlGiw9pY141BlK+68KJ2nAhkEC/c8slPCISVwiCcHobrFho8P1+CW3FRuqn6W9OhgzMyIxBu7yiGlVB2HNOKl7SUI9jfjuun6PtaSTmPhnsfkvh2n9nPiFF7eWQqXlLhjNm8nD+SGGSkoquvAPj6CoEFo6ujBuv1VuH5GCkKsFtVxyEtYuOcRFxqAhLAAw2+AYXe68MrOUiweG4u06CDVcXzSsuxEWC0m/HsX1+TShb2+qww9DhdPBTIYFu4FZKeEY19Zs+oYSn18qAZ1bd2cSXkeYQF+uHxSAtbuq0K3g2ty6dxcLonV20sxKzMK4xJCVcchL2LhXsD0tEgUN3Siob1bdRRlXtxWjJTIQCwy6L7Jg3VDTgpauuz47Eit6ijkwzYX1KG0sRN3cXRrOCzcC5iRFgEA2FParDSHKsdr2rDjZCPunJMOs0H3TR6s+aNjEB9mxRu7uCaXzm319hLEhFhx+aQE1VHIy1i4F5CdEgGLSWB3aZPqKEqs3l4Cf4sJN+cae9/kwTCbBK6bnoKNx+tQ12bcOyJ0buVNnfjsaC1unZnKfZMNiP/GLyDQ34wJiWGGLNz2bgfe3F2B5VMSERXsrzqOJtyYkwynS+LdfZWqo5APemVnKQSA22Zz32QjYuEOwoy0COwra4HD6VIdxave2lOB9m4H7uRkqUEbHReKSUlhLFz6im6HE6/mlWHphHgkRwSqjkMKsHAHYUZ6JLrsThytblMdxWuklFi9rQSTk8MwPTVCdRxNuXZaEvaVNaO4vkN1FPIhHx2qQX17D5cCGRgLdxBmpPXuc7rHQLeV84qbcKymDXfN4bZzQ3X11CQIAY5yqZ9X80qREhmIBaNjVEchRVi4g5ASGYiYECt2G2im8kvbSxAaYME1U7nt3FAlhgdiVkYU3t5bwa0eCQBQ2tCJLYUNuCU3FSbO9jcsFu4gCCEwIy3CMBOnatts+PBgFW7KSUWgP/dNHo5rpyXjRF0H9+EmAMBr+WUwCeDG3BTVUUghFu4gzUiPRElDJ+oNsAHGqzvLYHdK3DmHMymH68rJCfAzC95WJjicLry+qwyLx8UhMZyTpYzsgoUrhHhUCJEnhGgVQtQJIdYKISZ7I5wvOXVeZX6xvke5DqcLL+8sxfzRMciKDVEdR7Mig/2xaGws3t1bCZeLt5WNbNPxOtS0duOWmVzLbnSDGeEuBvAUgLkALgbgAPCpECLKg7l8TnZKBAL8TNhxskF1FI/69Egtqlps3DfZDa6ZlozqVht2FjeqjkIKrckrQ0yIFReP59aoRnfBwpVSXi6l/KeU8qCU8gCAuwDEApjn8XQ+xN9iwoy0SGw/oe8fni9tL0ZSeACW8ofDiF0yIQ5B/ma8s5cH0xtVbasN64/W4sacFPiZ+QTP6IbzHRDa9/f0fW91ALMzo3G0uhUtnXbVUTyisLYdWwobcPvsNFj4w2HEgvwtuGxiPN4/UM0ThAzq9V3lcLokbycTgOEV7hMA9gLY5t4ovm92VhSkhG5vEa7eXgI/s8AtMzlZyl2unZ6Mli47Nh+vVx2FvMzlkngtvwxzsqKQGROsOg75ADGUdYJCiN8DuBXAfCnliXN8zSoAqwAgPj4+Z82aNe7ICQBob29HSIi6iTw9TokHP+vE0jQLbhtvVZbjFHdej26HxHc2dmJqrBkPTA1wy2t6m+rvj4E4XBLf3dCJCdFmPDjNe9fVF6+FSiqux5EGJ/4vz4ZV2VbMTbJ49b0vhN8fp7n7WixZsmSXlDJ3oM8N+rtACPEH9JbtknOVLQBIKZ8B8AwA5ObmysWLFw8t7Xls3LgR7ny94cgp3IaKHgcWL16gNAfg3uvx8o5SdDkO4HvXzkJuhjbnw/nC98dAVrQexOu7ypB70XyEWL3zg9dXr4UqKq7HW2v2ICygFo/ctAQBfr61np3fH6d581oM6payEOIJALcDuFhKedSzkXzb7KxoHK5sRatNP89xpZR4cVsxJiSGIadv+RO5zzXTkmCzu/DZkRrVUchLmjt78MHBalw3PdnnypbUGcw63L8AuBfAbQCahBAJfX8MeT9iTmYUXBLI19Fz3F0lTThazX2TPSUnLRIJYQFYu69KdRTykrf3VKDH4eJ8COpnMCPcB9E7M/kzAFVn/PmeB3P5rOlpkfAzC10tD3ppewlCrRasmJ6kOooumUwCV2UnYvPxOrR06efOCA1MSok1eWXITgnHxKQw1XHIhwxmHa44x5+feCGfzwn0N2N6WiS2FOpj1mldWzfeP1CFG3JSEOTvWxM79OSq7ET0OF349DBvK+vd/vIWHK1u41Ig+gouthyGhWNicKiyVRf7Kr+W37tvMneW8qzpqRFIjgjEuv3cW1nv1uSVIdDPjGum8o4R9cfCHYaFY2MBQPOjXIfThX9tL8G80dEYxX2TPUoIgeXZifi8oB7NnT2q45CHdHQ78O7eClyVnYjQAD/VccjHsHCHYVJSOCKD/DS/mcEnh2tQ2WLD3RdlqI5iCFdlJ8Lhkvj4EG8r69V7+6vQ0ePErbydTANg4Q6D2SQwb3QMPi+o0/QB4//YchKpUYG4ZEK86iiGMCU5HGlRQVjL28q6tSavFKNig7m8jgbEwh2mhWNiUdvWjWM1baqjDMv+8mbkFTfhnrmZMJu4FMgbTt1W3lrUgAYdPP+n/o7XtGF3aTNunZnG5XU0IBbuMC0YGwMA+Fyjt5X/uaUYIVYLbs5NUR3FUK7KToTTJfHhoWrVUcjNXs0rg59Z4PoZyaqjkI9i4Q5TYnggxsSFYOPxWtVRhqym1YZ1+ytxU24KJ3Z42cTEMGTFBOO9/dwEQ0+6HU68ubscl01MQHSI+n3WyTexcEdg6YR47DjRqLltHldvL4HDJXHP3AzVUQzn1G3l7ScaUNfG28p68cnhGjR12rn2ls6LhTsCl06Mg8MlselYneoog2azO/GvHaVYOj4e6dE8MkyFq7KT4JLABwc5ytWLV/PKkBwRiPmjY1RHIR/Gwh2BaamRiA72x6ca2pT+3b2VaOzowX3zM1RHMaxxCaEYExeCdbytrAtljZ34vKAeN+emwsQJiHQeLNwRMJsELh4fhw1Ha2F3ulTHuSCXS+LvX5zA+IRQXJQVrTqOoS3PTkJecSNqWm2qo9AIvZZfBiGAmzgBkS6AhTtCl0yMR6vNgTwNnB60/mgtjte044FFo7hsQbGrshMhJTh5SuMcThdezy/HorGxSIoIVB2HfBwLd4QWjImBv8WETzSwKf1fNxUhOSIQy7MTVUcxvNFxIRifEIr3DrBwtWxzQR2qW23cWYoGhYU7QkH+FiwcE4MPD1bD5fLdXafyihuRX9KEVQuzYDHzX7svuHpqEnaVNKGyuUt1FBqmNTvLEBPij4vHc7c2ujD+5HWD5dlJqGqxYXdpk+oo5/T0xiJEBfvj5lz+Ju4rrprSe6eBt5W1qbbNhs+O1uKGGSnwt/BHKV0Yv0vc4JKJ8bBaTFi7zzf3yD1a3Yr1R2txz9wMBPqbVcehPhkxwZicHIZ1vK2sSW/sqoDTJXEzbyfTILFw3SDEasHSCXF470A1nD54W/lvm04gyN+Mu3nmrc9Znp2EfWXNKGvsVB2FhkBKiVfzSjErI4pHW9KgsXDdZHl2Eurbu7HjRIPqKP0U13fg3X2VuG1WGiKC/FXHobOcuq3MNbnasuNkI4obOrmzFA0JC9dNloyLQ7C/Ge/62G3lP60vgJ9Z4P5FWaqj0ABSo4IwNTUC63hkn6a8mleG0AALlk3hjH8aPBaumwT6m3H55AS8t78KXT1O1XEAAEV17Xh7TwXumpOOuNAA1XHoHK7OTsShylacrO9QHYUGoaXTjvcPVGHFtGTOiaAhYeG60a0z09DW7cD7PjIJ5k+fFcBqMeP+RaNUR6HzODVKWudjd0doYG/vrUC3w8XbyTRkLFw3mpkRiayYYLyaV6Y6Co7XtOHdfZX42twMxPC4MJ+WFBGI3PRIPsfVACklXtlZisnJYZicHK46DmkMC9eNhBC4ZWYqdhY3oqiuXWmWP356HEF+Zty/kM9utWB5diKO1bShoKZNdRQ6jwMVLTha3YZbZqapjkIaxMJ1s+tnpMBiEkpHubtKmvD+gWqsXJCFyGDOTNaCZVMSIQSwlqNcn7YmrwwBfiZcMzVJdRTSIBaum8WGWnHpxHi8ll+Gzh6H199fSonH3zuM2FArR7caEhcWgNmZUVi3vxJS+t5abgI6exx4d28llk1JRHign+o4pEEsXA9YOT8TzZ12vLG7wuvv/d6BKuwpbcZ/XTYOwVaL19+fhm95dhJO1HXgSBVvK/ui9/ZXob3bgVt5O5mGiYXrATnpkZiaGoF/fHHSqwca2OxO/OqDoxifEIobcng2p9ZcOTkBZpPgmlwf9WpeGbJigjEzI1J1FNIoFq4HCCHw9fmZOFnfgU+PeO/Yvr9tOoHypi48dtVEmE0871ZrokOsmDsqGuv2V/G2so8prG1DfkkTbpmZyrOkadhYuB5y5eQEpEcH4YnPCrzyw/NkfQf+srEQy7MTMX9MjMffjzxjeXYiShs7caCiRXUUOsOreWWwmASun8E7RzR8LFwPsZhN+PbFY3CoshUfHfLsKFdKicfePgCr2YQfLZ/o0fciz7p8UgIsJsE1uT6kx+HCG7srcMmEeMSGck07DR8L14OunZaErNhg/PHT4x49Rej1/HJsKWzA968cj7gwbuGoZRFB/lgwJgbv8bayz/jkcA0aO3pwyyzuLEUjw8L1IIvZhEcuHYuj1W1Yk1fqkfcobejET9cewpysKNwxi7Mn9WB5dhIqmruwu7RZdRQCsCavFEnhAVg4JlZ1FNI4Fq6HXTUlEbMzo/Dbj46hubPHra/tdEl897W9MJkEfnfzNJg4UUoXLp0UD3+zibOVfUBZYye+KKzHTbmpnIhII8bC9TAhBH567SS02hz41QdH3frabxbYsaukCT+7djKSIwLd+tqkTliAHxaNi8X7B6q8uqyMvur1/N4d427K5WQpGjkWrheMTwjD1xdkYk1eGT457J4JVO/srcB7J+24fXYaVkxPdstrku9Ynp2ImtZu5BU3qo5iWA6nC6/ll2PBmFikRAapjkM6wML1kkcuHYuJiWH4wRv7UdNqG9Fr7Strxg/e2I+xkSb85OpJbkpIvuSSCfEI8DNxtrJCmwvqUN1qw208ho/chIXrJVaLGU/cOg02uxMrX8gb9j7LR6pacfc/diImxIqHpgXA38J/hXoUbLXg4vFx+OBgFRxOl+o4hvTKzjLEhPhj6YR41VFIJ/jT2ovGxIfiydum43BlKx76127Y7M4h/f3dpU244+87EOhnxivfmINwKydx6Nny7CTUt/dgx0neVva22lYb1h+txQ05KfylltyG30letnRCPH62YjI2HKvD3f/YiZZO+wX/jpQSb+4ux23PbEeI1YJXVs1BahSfKendknFxCPI3c7ayAq/vKofTJXlQAbkVC1eBO2an40+3Tcee0iZc+cRmrD9ac85NDkobOvHA6l145LV9yE4Jx1sPzkVmTLCXE5MKgf5mLJ0Qjw8OVsPO28pe43JJrMkrxZysKP5/jdyK57cpcs3UJKRGBuI/X9uH+57Px5TkcFw5JQHj4kNhNgmUNXZi0/E6bDhWB4tJ4IdXjsc3FmRxLaDBLM9OxNp9ldha1IBFY7nxgjdsLWpAWWMXvnfZONVRSGdYuApNT4vEh99ZiNfyy7AmrxS//vBYv88nhgfg6/MzsXJ+JrdsNKhFY2MRarVg3b5KFq6XvJJXioggP1w+KUF1FNIZFq5i/hYT7pyTjjvnpKOhvRsljZ1wuSQSIwKRFB7Ao8AMLsDPjEsnxuOjQ9V4/LrJsFrMqiPpWkN7Nz4+VI0756QjwI/XmtyLz3B9SHSIFTPSIpGbEYXkiECWLQEArp6WhFabAxuP1amOontv7q6A3SlxG/clJw9g4RL5uAWjYxAd7I939laojqJrUkq8kleKGWkRGBsfqjoO6RALl8jHWcwmXD01CZ8eqUWr7cLLyGh48oqbcKKuA7dydEsewsIl0oBrpyWhx+HChweqVUfRrTU7SxFqtWB5dqLqKKRTLFwiDZiWGoH06CC8zdvKHtHSacd7B6pwzbQkBPlzLil5BguXSAOEEFgxLRnbTjSgumVkh1/QV729twLdDhcnS5FHsXCJNGLF9GRICby7j6Ncd5JS4pWdpZicHIbJyeGq45COsXCJNCIzJhhTU8Lx9h7urexOu0ubcbS6jaNb8jgWLpGGrJiejMNVrThe06Y6im78a3sJQqwWrJiWrDoK6RwLl0hDlmcnwWwSeHsPbyu7Q2NHD9btr8L1M5IRbOVkKfIsFi6RhsSGWjFvdAze2VsJl2vgE6Zo8F7PL0OP04U756SrjkIGwMIl0pjrpiehorkL+SVNqqNomssl8fLOUszKiOLOUuQVLFwijblsYgIC/cxckztCnxfWo6ShE3fM4WQp8g4WLpHGBFstuGxSPN7bXwWb3ak6jmat3l6C6GB/XDGZx/CRd7BwiTTohhkpaOmy47MjtaqjaFJFcxc+O1KDm2em8shD8hoWLpEGzRsdg8TwALy+q0x1FE1as7MUEsDtXHtLXsTCJdIgs0ng+hnJ2Hy8jls9DpHd6cKavDIsGReH1Kgg1XHIQFi4RBp1Y04qXBJ4c0+56iia8vGhGtS1deNOTpYiL2PhEmlUZkwwZmZE4t/55ZCSa3IH66XtxUiOCMSisXGqo5DBsHCJNOymnFScqO/A7lKuyR2MI1Wt2H6iEXfOSYfZJFTHIYNh4RJp2LLsRAT6mfF6Pm8rD8bzW4oR4GfCbbNSVUchA2LhEmlYiNWCZVMSsW5/FTp7HKrj+LTGjh68vbcC101PQUSQv+o4ZEAsXCKNuyk3Be3dDnx0qFp1FJ/2ys5SdDtcuGduhuooZFAsXCKNm50ZhbSoIN5WPg+HS+KlbSWYNzoa4xK4bzKpwcIl0jghBG7KScHWogaUNHSojuOTdtc4Ud1qw71zM1VHIQNj4RLpwM0zU2E2Cby8s1R1FJ/0cYkdaVFBWDKeS4FIHRYukQ7EhwXg0gnxeD2/HN0OHmhwpv3lzShsduFrczO4FIiUYuES6cQdc9LQ2NGDDw9y8tSZnt9SjABz7+QyIpUGXbhCiAeFECeFEDYhxC4hxAJPBiOioZk3Kgbp0UH41w7eVj6lqqULa/dXYn6yBWEBfqrjkMENqnCFELcAeALALwBMB7AVwAdCCG5GSuQjTCaB22elYefJRlS0u1TH8Qn/3FIMp0vi8gyWLak32BHuIwCel1I+K6U8IqX8FoAqAN/0XDQiGqobc1LgbzZhY5lddRTlWm12vLyjFFdlJyE2iE/PSL0LfhcKIfwB5AD4+KxPfQxgridCEdHwRIdYceWUBGypcKCrx9iTp17eUYr2bgfuX5ilOgoRAEBc6JQRIUQSgAoAi6SUm8/4+I8A3CGlHHfW168CsAoA4uPjc9asWeO2sO3t7QgJCXHb62kdr0d/vB69jjU68cudNqyc7I8FKca8lWp3SfzXpi4khQh8f2YgvzfOwutxmruvxZIlS3ZJKXMH+pxlCK9zdjOLAT4GKeUzAJ4BgNzcXLl48eIhvMX5bdy4Ee58Pa3j9eiP16PXIinx4uEPsKMpAI/dMR9CGG8pzGv5ZWju3o8/3TETC8fG8nvjLLwep3nzWgzmwUY9ACeAhLM+Hgegxu2JiGhEhBC4NN0PBytakVdsvGP7XC6JZzafwITEMCwYE6M6DtGXLli4UsoeALsAXHrWpy5F72xlIvIxc5MsiAzyw3NfnFAdxes2HKtFYW077l+YZcjRPfmuwU7d+z2Ae4QQXxdCTBBCPAEgCcBfPReNiIbL3yxw++w0fHy4BqUNnarjeI2UEk+uL0RyRCCuyk5UHYeon0EVrpTyVQDfAfAYgL0A5gNYJqUs8VgyIhqRuy/KgFkIPL+1WHUUr/misB57y5rx4JJR8DNzKRD5lkF/R0opn5JSZkgprVLKnDNnLBOR74kPC8Dy7ES8ll+GNpv+1+VKKfHEpwVIDA/AjTncxpF8D38FJNKx++Znor3bgdcMcFbuthMNyC9pwjcXj4LVYlYdh+grWLhEOpadEoGZGZH455aTcDj1vd3jnz4rQFyoFTfnpqqOQjQgFi6Rzq1aOArlTb2b+OvVjhMN2H6iEQ8sGoUAP45uyTexcIl0bun4OIxPCMVTG4rgcp1/ZzmteuKzAsSEWHHbLJ6nQr6LhUukcyaTwDcXj0JBbTs+Pqy/vWq+KKjH1qIGPLh4FAL9Obol38XCJTKA5dlJyIgOwlMbC3Gh/dO1REqJX390FMkRgbhjDke35NtYuEQGYDYJPLBoFPaXt+DzgnrVcdzmw4PV2F/egu9cMoYzk8nnsXCJDOK6GclICAvAnz4r0MUo1+F04TcfH8PouBBcP4Prbsn3sXCJDMJqMeOhi0cjv6QJG4/XqY4zYm/sLseJug5877JxMJu4ZzL5PhYukYHckpuKtKgg/PajY5qesdze7cBvPz6OaakRuHxSvOo4RIPCwiUyEH+LCd+9dAwOVbbig4PVquMM2182FKKurRs/vnoiTwQizWDhEhnMNVOTMTY+BL/75Jgmd58qbejEc5+fxPXTkzE9LVJ1HKJBY+ESGYzZJPCfl43DiboO/HuX9vZY/sX7R2A2CXz/ivGqoxANCQuXyIAumxiPGWkR+O3HxzV1ktDWonp8eKgaDy0ZhYTwANVxiIaEhUtkQEII/PjqSahv78af1xeqjjMoNrsTj711EKlRgfj6gizVcYiGjIVLZFBTUyNwY04K/rHlJE7Wd6iOc0FPbSzCifoO/HzFFB5QQJrEwiUysO9fMQ5Wixk/W3dYdZTzKqxtw9MbC7FiWhIWjo1VHYdoWFi4RAYWFxqAh5eOwfqjtfjgQJXqOANyuiR++MYBBFsteGz5RNVxiIaNhUtkcPfOy8Dk5DD87zuH0NzZozrOVzyz+QTyS5rwo+UTERNiVR2HaNhYuEQGZzGb8OsbpqK5swc/W3dEdZx+Dla04PefHMOyKQm4bnqy6jhEI8LCJSJMTArDA4tG4Y3d5dhwtFZ1HAC9s5K/++peRAb54+crpnBHKdI8Fi4RAQD+4+LRGBcfiu+9vg+1rTbVcfCTdw+hoLYdv74xG5HB/qrjEI0YC5eIAAABfmb8+fbp6Ohx4Duv7oVT4eEGa3aWYk1eGR5aMgqLx8Upy0HkTixcIvrSmPhQ/PSaSdha1IC/bFCzIca+smb86J1DWDAmBo9cOk5JBiJPYOESUT8356bi2mlJ+MOnx/HxIe+eKFTR3IVVL+UjNtSKJ26dznNuSVdYuETUjxACv7o+G1OSw/Hwmr04WNHilfdt7uzB1/6xE509Tjx3Ty6i+NyWdIaFS0RfEehvxt/vzkVkkB/uez4PxR7e+rHNZsd9z+ehtKETz9yVi/EJYR59PyIVWLhENKC4sAA8f98sOFwStz27HaUNnR55n5YuO+58bif2l7fgT7dNw0Wjoj3yPkSqsXCJ6JzGxodi9crZ6LI7ccsz23CkqtWtr1/R3IVbn9mOw5UtePrOHFwxOdGtr0/kS1i4RHReE5PC8PLX58AlJW58eqvbNsbYVdKIa/+8BeWNnXjuazNx6cR4t7wuka9i4RLRBU1MCsM7D81HRkww7n0+Dz9dewg2u3NYr9XtcOK3Hx3DzX/bjhCrGW89NJcnAJEhWFQHICJtSAgPwL8fmItffXAE/9xSjI3H6vCDK8bh8kkJg9p2UUqJTw7X4NcfHUNhbTtuzEnB/y6fiPBAPy+kJ1KPhUtEgxbob8ZPr52MSycm4CdrD+GB1bsxJi4Et8xMxSUT4pEeHdSvfKWUKG7oxPqjtVizsxQFte3IignGP+7JxcXjeQuZjIWFS0RDNn9MDD58eAHe2VuJF7eX4PH3juDx944gOtgfqVFBCPAzocvuQlljJxo7eo/8m5oagd/eNBUrpiXBYubTLDIeFi4RDYvFbMINOSm4IScFJ+rasaWwHgcrWlHR3IUepwuhVgsunxSPiYlhWDAmFhkxwaojEynFwiWiEcuKDUFWbIjqGEQ+jfd1iIiIvICFS0RE5AUsXCIiIi9g4RIREXkBC5eIiMgLWLhERERewMIlIiLyAhYuERGRF7BwiYiIvICFS0RE5AUsXCIiIi9g4RIREXkBC5eIiMgLWLhERERewMIlIiLyAhYuERGRF7BwiYiIvICFS0RE5AVCSum5FxeiDkCJG18yBkC9G19P63g9+uP1OI3Xoj9ej/54PU5z97VIl1LGDvQJjxauuwkh8qWUuapz+Apej/54PU7jteiP16M/Xo/TvHkteEuZiIjIC1i4REREXqC1wn1GdQAfw+vRH6/HabwW/fF69MfrcZrXroWmnuESERFpldZGuERERJrEwiUiIvICzRauEOJZIUSREKJLCFEnhHhHCDFBdS5vE0JECSGeFEIc7bsWZUKIp4UQ0aqzqSKEWCWE2CCEaBZCSCFEhupM3iSEeFAIcVIIYRNC7BJCLFCdSQUhxEIhxLtCiIq+74N7VGdSRQjxqBAiTwjR2vfzcq0QYrLqXKoIIR4SQuzvux6tQohtQoirPP2+mi1cAPkA7gEwAcDlAASAT4UQfipDKZAEIBnA9wFMAXAngIUAXlEZSrEgAB8D+IniHF4nhLgFwBMAfgFgOoCtAD4QQqQpDaZGCICDAB4G0KU4i2qLATwFYC6AiwE40PvzMkplKIXKAfwAwAwAuQDWA3hbCJHtyTfVzaSpvgu1D8B4KeUx1XlUEkIsA7AOQISUslV1HlWEELkA8gBkSimLFcfxCiHEDgD7pZTfOONjBQD+LaV8VF0ytYQQ7QD+Q0r5vOosvkAIEQKgBcAKKeVa1Xl8gRCiEcCjUsq/eeo9tDzC/ZIQIhjAvQBKARSrTeMTwgB0A+hUHYS8RwjhDyAHvaP7M32M3pEN0Smh6P3536Q6iGpCCLMQ4lb03hHZ6sn30nTh9j2ragfQDuBKAEullN2KYyklhIgA8DMAz0opHYrjkHfFADADqDnr4zUAErwfh3zYEwD2AtimOIcyQogpff3RDeCvAK6TUh7w5Hv6VOEKIR7vm9xwvj+Lz/gr/0Lvc6pFAI4DeF0IEaQgutsN41qcGumvBVCB3me6ujGc62FgZz8nEgN8jAxKCPF7APMB3CCldKrOo9AxANMAzAHwNIAXPD2RzOLJFx+GPwJYfYGvKT31X6SULeh9DlEghNiO3tsjNwB4yVMBveiPGMK16Hsm837fPy6XUto8lEuVP2II18Og6gE48dXRbBy+OuolAxJC/AHArQCWSClPqM6jkpSyB0Bh3z/mCyFmAvgugJWeek+fKlwpZT2Gf0yS6PtjdV8idYZyLYQQoQA+QO///iuklO2ezKbCCL83DEFK2SOE2AXgUgCvn/GpSwG8oSYV+QohxBPoLdvFUsqjqvP4IBM83B8+VbiDJYQYjd6R7KcA6gCkAPgheu/Fr1MYzev6yvZj9E6UWgEguO/WMgA09v0WZyhCiAT0jvLG9n1oYt+z7VIpZaOyYN7xewAvCSF2AtgC4AH0Lh37q9JUCvTd9Rnd948mAGlCiGno/f+Foe6GCCH+AuAu9P6MaOr7/wgAtOvxF/QLEUL8CsB7AMrQO4HsdvQunfLoWlxNLgsSQqSid8PpHAAR6L1dthnAz4z2m1vfc8sN5/j0EinlRq+F8RFCiJ8A+PEAn7rXCMtChBAPovcZfiJ616F+V0q5WW0q7zvP/zdekFLe49UwigkhzvWD/qdSyp94M4svEEI8D2AJen8xbwGwH8BvpJQfefR9tVi4REREWuNTs5SJiIj0ioVLRETkBSxcIiIiL2DhEhEReQELl4iIyAtYuERERF7AwiUiIvICFi4REZEXsHCJiIi8gIVLRETkBSxcIh0QQnzcdybw9Wd9XAghnu/73K9U5SMi7qVMpAtCiKkAdqP3UO0ppw4WF0L8DsAjAJ6VUq5SGJHI8DjCJdIBKeU+AC8BmIDeY9gghPhv9Jbta+g9po+IFOIIl0gnhBApAArQe1zlbwE8CeAjANcY8VxkIl/DwiXSESHELwH8sO8ftwK4VErZqTASEfXhLWUifak747+vZNkS+Q4WLpFOCCFuQ++t5Oq+Dz2sMA4RnYWFS6QDQohlAF4AcAhANoCjAL4uhBivNBgRfYmFS6RxQoj5AP4NoBzAZVLKOgD/C8ACgGtviXwEJ00RaVjf+ttNALoAzJdSFp3xuTwAuQAWSik/VxSRiPpwhEukUUKI0ehd9iMBXH5m2fZ5tO8/f+PVYEQ0II5wiYiIvIAjXCIiIi9g4RIREXkBC5eIiMgLWLhERERewMIlIiLyAhYuERGRF7BwiYiIvICFS0RE5AUsXCIiIi9g4RIREXnB/wfh5yV+khy9SAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining the function using a 'lambda' definition.\n",
    "f = lambda x: (x - 2)*np.sin(2*x) + np.power(x,2)\n",
    "\n",
    "# Defining the grid for plotting, the number '1000' indicates the number of points of the sample. \n",
    "# Suggestion: Change it and see what happends! For instance, what about if you change to 10?\n",
    "xx = np.linspace(-3,3,1000)\n",
    "# Plotting the function\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(xx,f(xx),'-',label=r'$f(x)$')\n",
    "plt.grid(True)\n",
    "plt.xlabel('$x$')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create an interactive use of the Gradient Descent in 1D where you could define the initial guess $x_0$, the scaling factor $\\alpha$ and the iteration number.\n",
    "In this numerical experiment we will the importance of the coefficient $\\alpha$, and how it is related to the 'gradient' and the initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660a49f0e524944a1ea128db03991b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='x0', max=3.0, min=-3.0), FloatSlider(value=1.0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.GD_1D(x0=2, alpha=1, n=0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GD_1D(x0=2, alpha=1, n=0):\n",
    "    \n",
    "    # Defining the function using a 'lambda' definition and its derivative.\n",
    "    f = lambda x: (x-2)*np.sin(2*x)+np.power(x,2)\n",
    "    fp = lambda x: 2*x+2*(x-2)*np.cos(2*x)+np.sin(2*x)\n",
    "    \n",
    "    # Plotting the function and its derivative.\n",
    "    xx = np.linspace(-3,3,1000)\n",
    "    plt.figure(figsize=(14,7))\n",
    "    \n",
    "    ax = plt.subplot(1,2,1)\n",
    "    plt.plot(xx,f(xx),'b-',label=r'$f(x)$')\n",
    "    # Warning: The 'alpha' parameter for the plt.plot function corresponds to\n",
    "    # a transparency parameter, it is not related to the alpha parameter of\n",
    "    # the Gradient Descent explained before.\n",
    "    plt.plot(xx,fp(xx),'r-',label=r\"$f'(x)$\", alpha=0.5)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('$x$')\n",
    "    plt.title('Plot in linear scale')\n",
    "    \n",
    "    # Plotting outcome with no iterations\n",
    "    plt.plot(x0,f(x0),'k.',markersize=10,label=r'$x_i$')\n",
    "    plt.plot(x0,fp(x0),'m.',markersize=10,label=r\"$f'(x_i)$: 'Gradient'\")\n",
    "    ax = plt.subplot(1,2,2)\n",
    "    plt.semilogy(xx,np.abs(f(xx)),'b-',label=r\"$|f(x)|$\")\n",
    "    plt.semilogy(xx,np.abs(fp(xx)),'r-',label=r\"$|f'(x)|$\", alpha=0.5)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('$x$')\n",
    "    plt.title('Plot in logarithmic scale')\n",
    "    plt.semilogy(x0,np.abs(f(x0)),'k.',markersize=10,label=r'$x_i$')\n",
    "    plt.semilogy(x0,np.abs(fp(x0)),'m.',markersize=10,label=r\"$|f'(x_i)|$: 'Gradient'\")\n",
    "    \n",
    "    # Computing steps of Gradient Descent\n",
    "    if n>0:\n",
    "        xi_output=np.zeros(n+1)\n",
    "        xi_output[0]=x0\n",
    "        for k in range(n):\n",
    "            fp_x0=fp(x0)\n",
    "            x1 = x0-alpha*fp_x0\n",
    "            xi_output[k+1]=x1\n",
    "            x0 = x1\n",
    "        ax = plt.subplot(1,2,1)\n",
    "        plt.plot(xi_output,f(xi_output),'k.-',markersize=10,label=r'$x_i$')\n",
    "        plt.plot(xi_output,fp(xi_output),'m.',markersize=10)\n",
    "        ax = plt.subplot(1,2,2)\n",
    "        plt.semilogy(xi_output,np.abs(f(xi_output)),'k.-',markersize=10,label=r'$x_i$')\n",
    "        plt.semilogy(xi_output,np.abs(fp(xi_output)),'m.',markersize=10)\n",
    "        \n",
    "    \n",
    "    # Plotting outcome\n",
    "    ax = plt.subplot(1,2,1)\n",
    "    plt.legend(loc='best')\n",
    "    ax = plt.subplot(1,2,2)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "interact(GD_1D,x0=(-3,3,0.1), alpha=(0,10,0.01), n=(0,100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What conclusions could be draw?\n",
    "\n",
    "The main conclusion that can be draw is the importance of the selection of the parameter $\\alpha$ for the success of the task of finding a minimum of a function.\n",
    "Also, as ussual, the initial guess $x_0$ will help us to select different local minima.\n",
    "\n",
    "Question to think about:\n",
    "- What could happen if you normalize the 'gradient'? In 1D this would be computing the following coeficients: $GN=\\frac{f'(x_i)}{|f'(x_i)|}$, this will gives us the 'direction' where we should move (in 1D is just the sign of the derivative), then the coefficient $\\alpha$ may control a bit more the magnitude of each step from $x_i$ to $x_{i+1}$. So, how do we undertand this? Implement it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='GD_2D_LinearLeastSquare' />\n",
    "\n",
    "## Gradient Descent for a 2D linear least-square problem\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "In this case we will solve the following least-square problem:\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "        1 & x_1 \\\\\n",
    "        1 & x_2 \\\\\n",
    "        1 & x_3 \\\\\n",
    "        \\vdots & \\vdots \\\\\n",
    "        1 & x_m\n",
    "    \\end{bmatrix}}_{\\displaystyle{A}}\n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "        a\\\\\n",
    "        b\n",
    "    \\end{bmatrix}}_{\\mathbf{x}}\n",
    "    =\n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "        y_1 \\\\\n",
    "        y_2 \\\\\n",
    "        y_3 \\\\\n",
    "        \\vdots\\\\\n",
    "        y_m \n",
    "    \\end{bmatrix}}_{\\displaystyle{\\mathbf{b}}}.\n",
    "\\end{equation}\n",
    "$$\n",
    "This overdetermined linear least-square problem can be translated to the following form:\n",
    "$$\n",
    "\\begin{equation}\n",
    "    E(a,b)=\\left\\|\\mathbf{b}-A\\,\\mathbf{x}\\right\\|_2^2=\\sum_{i=1}^m (y_i-a-b\\,x_i)^2.\n",
    "\\end{equation}\n",
    "$$\n",
    "Now, to apply the Gradient Descent algorithm we need to compute the Gradient of $E(a,b)$ with respect to $a$ and $b$, which is the following,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial E}{\\partial a} &= \\sum_{i=1}^m -2\\,(y_i-a-b\\,x_i),\\\\\n",
    "    \\frac{\\partial E}{\\partial b} &= \\sum_{i=1}^m -2\\,x_i\\,(y_i-a-b\\,x_i).\n",
    "\\end{align*}\n",
    "$$\n",
    "Notice that in this case we don't want to cancel out the \"-\" (minus) sign since it will change the direction of the Gradient.\n",
    "Now, we have everything to apply the Gradient Descent in 2D.\n",
    "For comparison purposes, we will also include the solution obtain by the normal equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f885eb4a83094869b69c480b409bd53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='a0', max=4.0, min=-4.0), FloatSlider(value=2.0, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.GD_2D_linear(a0=2, b0=2, alpha=0, n=0, m=10)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GD_2D_linear(a0=2, b0=2, alpha=0, n=0, m=10):\n",
    "    \n",
    "    # Building data.\n",
    "    np.random.seed(0)\n",
    "    xi = np.random.normal(size=m)\n",
    "    yi = -2+xi+np.random.normal(loc=0, scale=0.5, size=m)\n",
    "\n",
    "    # Defining matrix A and the right-hand-side.\n",
    "    # Recall that we usually denote as b the right-hand-side but to avoid confusion with\n",
    "    # the coefficient b, we will just call it RHS.\n",
    "    A = np.ones((m,2))\n",
    "    A[:,1] = xi\n",
    "    RHS = yi\n",
    "    \n",
    "    # Defining the Gradient\n",
    "    E = lambda a, b: np.sum(np.power(yi-a-b*xi,2))\n",
    "    G = lambda a, b: np.array([np.sum(-2*(yi-a-b*xi)), np.sum(-2*xi*(yi-a-b*xi))],dtype=float)\n",
    "    # This fucntion will help us to evaluate the Gradient on the points (X[i,j],Y[i,j])\n",
    "    def E_mG_XY(AA,BB):\n",
    "        Z = np.zeros_like(AA)\n",
    "        U = np.zeros_like(AA)\n",
    "        V = np.zeros_like(AA)\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                Z[i,j]=E(AA[i,j],BB[i,j])\n",
    "                uv = -G(AA[i,j],BB[i,j])\n",
    "                U[i,j] = uv[0]\n",
    "                V[i,j] = uv[1]\n",
    "        return Z, U, V\n",
    "    \n",
    "    # Plotting the function and its gradient.\n",
    "    # Credits: \n",
    "    #  https://matplotlib.org/stable/gallery/images_contours_and_fields/plot_streamplot.html\n",
    "    #  https://scipython.com/blog/visualizing-a-vector-field-with-matplotlib/\n",
    "    x = np.linspace(-5,5,m)\n",
    "    AA, BB = np.meshgrid(x,x)\n",
    "    fig = plt.figure(figsize=(14,10))\n",
    "    Z, U, V = E_mG_XY(AA,BB)\n",
    "    cont = plt.contour(AA,BB,Z, 100)\n",
    "    stream = plt.streamplot(AA, BB, U, V, color=Z, linewidth=2, cmap='autumn', arrowstyle='->', arrowsize=2)\n",
    "    fig.colorbar(stream.lines)\n",
    "    fig.colorbar(cont)\n",
    "    plt.scatter(a0, b0, s=300, marker='.', c='k')\n",
    "    my_grad = G(a0,b0)\n",
    "    my_title = r'$\\alpha=$ %.4f, $E(a,b)=$ %.4f, $\\nabla E(a,b)=$ [%.4f, %.4f]' %  (alpha, E(a0,b0), my_grad[0], my_grad[1])\n",
    "    plt.title(my_title)\n",
    "    \n",
    "    # Computing steps of Gradient Descent\n",
    "    if n>0:\n",
    "        ab_output=np.zeros((n+1,2))\n",
    "        z0 = np.array([a0,b0],dtype=float)\n",
    "        z0[0] = a0\n",
    "        z0[1] = b0\n",
    "        ab_output[0,:]=z0\n",
    "        # The Gradient Descent Algorithm\n",
    "        for k in range(n):\n",
    "            G_E_0=G(z0[0],z0[1])\n",
    "            z1 = z0-alpha*G_E_0\n",
    "            ab_output[k+1,:]=z1\n",
    "            z0 = z1\n",
    "            plt.scatter(z1[0], z1[1], s=300, marker='.', c='k')\n",
    "        plt.plot(ab_output[:,0],ab_output[:,1],'k-')\n",
    "        my_grad = G(ab_output[-1,0],ab_output[-1,1])\n",
    "        my_title = r'$\\alpha=$ %.4f, $E(a,b)=$ %.4f, $\\nabla E(a,b)=$ [%.4f, %.4f]' %  (alpha, E(ab_output[-1,0],ab_output[-1,1]), my_grad[0], my_grad[1])\n",
    "        plt.title(my_title)\n",
    "    plt.show()\n",
    "    \n",
    "interact(GD_2D_linear, a0=(-4,4,0.1), b0=(-4,4,0.1), alpha=(0,0.1,0.0001), n=(0,100,1), m=(10,100,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous implementation we used the following notation:\n",
    "- $n$: Number of iteration of Gradient Descent\n",
    "- Black dot: Solution $[a_n,b_n]$ at $n$-th step of the Gradient Descent.\n",
    "- Red-Yellow streamplot: Stream plot of the vector field generated by minus the Gradient of the error function $E(a,b)$\n",
    "- Blue-Green contour: Contour plot of the error function $E(a,b)$.\n",
    "\n",
    "Questions:\n",
    "- Try: $\\alpha=0.02$, $n=20$, and $m=10$. What do you observe? (keep initialization values of $a_0$ and $a_1$)\n",
    "- Try: $\\alpha=0.04$, $n=20$, and $m=10$. What do you observe? (keep initialization values of $a_0$ and $a_1$)\n",
    "- Try: $\\alpha=0.08$, $n=20$, and $m=10$. What do you observe? (keep initialization values of $a_0$ and $a_1$)\n",
    "- Can we use a large value of $\\alpha$?\n",
    "- How is related $\\alpha$ and the iteration number $n$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='GD_2D_NonLinearLeastSquare' />\n",
    "\n",
    "## Gradient Descent for a 2D nonlinear least-square problem\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "In this case, we will explore the use of the the Gradient Descent algorithm applied to a nonlinear least-square problem with an exponential fit.\n",
    "Let the function to be fit be,\n",
    "$$\n",
    "\\begin{equation}\n",
    "    y(t) = a\\,\\exp(b\\,t),\n",
    "\\end{equation}\n",
    "$$\n",
    "where the error function is defined as follows,\n",
    "$$\n",
    "\\begin{equation}\n",
    "    E(a,b)==\\sum_{i=1}^m (y_i-a\\,\\exp(b\\,t_i))^2.\n",
    "\\end{equation}\n",
    "$$\n",
    "Now, to apply the Gradient Descent algorithm we need to compute the Gradient of $E(a,b)$ with respect to $a$ and $b$, which is the following,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial E}{\\partial a} &= \\sum_{i=1}^m 2\\,\\exp(b\\,t_i)(a\\,\\exp(b\\,t_i)-y_i),\\\\\n",
    "    \\frac{\\partial E}{\\partial b} &= \\sum_{i=1}^m 2\\,a\\,\\exp(b\\,t_i)\\,t_i\\,(a\\,\\exp(b\\,t_i)-y_i).\n",
    "\\end{align*}\n",
    "$$\n",
    "As you may expect, this approach may create very large values for the gradient, which will be very challenging to handle them numerically.\n",
    "So, an alternative approach is the following,  which we will call it \"The Variant\":\n",
    "- Select an initial guess, say $\\mathbf{x}_0$\n",
    "- Compute the direction of fastest decrease: $\\mathbf{d}_0=-\\nabla f(\\mathbf{x}_0)$\n",
    "- Update the approximation $\\mathbf{x}_1=\\mathbf{x}_0+\\alpha\\,\\frac{\\mathbf{d}_0}{\\|\\mathbf{d}_0\\|}$\n",
    "- Iterate until certain threshold is achieved.\n",
    "Thus, the only change is on the magnitud of the **direction** vector used.\n",
    "In this case, it will be a unitary direction. \n",
    "This brings the advantage that $\\alpha$ now controls the **length** of the update.\n",
    "This is useful when you want to control the increment, otherwise it may require a very fine tuning of the parameter (or in general hyperparameter tuning!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0054b2f3f648548ed331409bfeb720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.75, description='a0', max=2.0, min=-2.0, step=0.01), FloatSlider(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.GD_2D_nonlinear(a0=0.75, b0=0.75, alpha=0, n=0, m=10, TheVariantFlag=False)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GD_2D_nonlinear(a0=0.75, b0=0.75, alpha=0, n=0, m=10, TheVariantFlag=False):\n",
    "    \n",
    "    # Building data.\n",
    "    np.random.seed(0)\n",
    "    a = 1.1\n",
    "    b = 0.23\n",
    "    y = lambda t: a*np.exp(b*t)\n",
    "    T = 10\n",
    "    ti = T*(np.random.rand(m)*2-1)\n",
    "    yi = y(ti)+np.random.normal(loc=0, scale=0.1, size=m)\n",
    "    \n",
    "    # Defining the Gradient\n",
    "    E = lambda a, b: np.sum(np.power(yi-a*np.exp(b*ti),2))\n",
    "    G = lambda a, b: np.array([np.sum(2*np.exp(b*ti)*(a*np.exp(b*ti)-yi)), np.sum(2*a*np.exp(b*ti)*ti*(a*np.exp(b*ti)-yi))],dtype=float)\n",
    "    # This fucntion will help us to evaluate the Gradient on the points (X[i,j],Y[i,j])\n",
    "    def E_mG_XY(AA,BB):\n",
    "        Z = np.zeros_like(AA)\n",
    "        U = np.zeros_like(AA)\n",
    "        V = np.zeros_like(AA)\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                Z[i,j]=E(AA[i,j],BB[i,j])\n",
    "                uv = -G(AA[i,j],BB[i,j])\n",
    "                U[i,j] = uv[0]\n",
    "                V[i,j] = uv[1]\n",
    "        return Z, U, V\n",
    "    \n",
    "    # Plotting the function and its gradient.\n",
    "    # Credits: \n",
    "    #  https://matplotlib.org/stable/gallery/images_contours_and_fields/plot_streamplot.html\n",
    "    #  https://scipython.com/blog/visualizing-a-vector-field-with-matplotlib/\n",
    "    x = np.linspace(-3,3,m)\n",
    "    AA, BB = np.meshgrid(x,x)\n",
    "    fig = plt.figure(figsize=(14,10))\n",
    "    Z, U, V = E_mG_XY(AA,BB)\n",
    "    cont = plt.contour(AA,BB,Z, 10)\n",
    "    stream = plt.streamplot(AA, BB, U, V, color=Z, linewidth=2, cmap='autumn', arrowstyle='->', arrowsize=2)\n",
    "    fig.colorbar(stream.lines)\n",
    "    fig.colorbar(cont)\n",
    "    plt.scatter(a0, b0, s=300, marker='.', c='k')\n",
    "    my_grad = G(a0,b0)\n",
    "    my_title = r'$\\alpha=$ %.4f, $E(a,b)=$ %.4f, $\\nabla E(a,b)=$ [%.4f, %.4f]' %  (alpha, E(a0,b0), my_grad[0], my_grad[1])\n",
    "    plt.title(my_title)\n",
    "    \n",
    "    # Computing steps of Gradient Descent\n",
    "    if n>0:\n",
    "        ab_output=np.zeros((n+1,2))\n",
    "        z0 = np.array([a0,b0],dtype=float)\n",
    "        z0[0] = a0\n",
    "        z0[1] = b0\n",
    "        ab_output[0,:]=z0\n",
    "        # The Gradient Descent Algorithm\n",
    "        for k in range(n):\n",
    "            G_E_0=G(z0[0],z0[1])\n",
    "            if not TheVariantFlag:\n",
    "                # Traditional GD\n",
    "                z1 = z0-alpha*G_E_0\n",
    "            else:\n",
    "                # The Variant! Why would this be useful?\n",
    "                z1 = z0-alpha*G_E_0/np.linalg.norm(G_E_0)\n",
    "            ab_output[k+1,:]=z1\n",
    "            z0 = z1\n",
    "            plt.scatter(z1[0], z1[1], s=300, marker='.', c='k')\n",
    "        plt.plot(ab_output[:,0],ab_output[:,1],'k-')\n",
    "        my_grad = G(ab_output[-1,0],ab_output[-1,1])\n",
    "        my_title = r'$\\alpha=$ %.6f, $E(a,b)=$ %.4f, $\\nabla E(a,b)=$ [%.4f, %.4f]' %  (alpha, E(ab_output[-1,0],ab_output[-1,1]), my_grad[0], my_grad[1])\n",
    "        plt.title(my_title)\n",
    "        print('GD found:',ab_output[-1,0],ab_output[-1,1])\n",
    "        \n",
    "    # Plotting the original data and the \"transformed\" solution\n",
    "    # Using the same notation from classnotes:\n",
    "    A = np.ones((m,2))\n",
    "    A[:,1]=ti\n",
    "    K_c2 =np.linalg.lstsq(A,np.log(yi), rcond=None)[0]\n",
    "    c1_ls = np.exp(K_c2[0])\n",
    "    c2_ls = K_c2[1]\n",
    "    print('Transformed Linear LS solution:',c1_ls, c2_ls)\n",
    "    plt.plot(c1_ls,c2_ls,'ms',markersize=20, label='Transformed Linear LS')\n",
    "    print('Original data:',a,b)\n",
    "    plt.plot(a,b,'bd',markersize=20, label='Original data')\n",
    "        \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "radio_button_TheVariant=RadioButtons(\n",
    "    options=[('Traditional GD',False),('The Variant GD',True)],\n",
    "    value=False,\n",
    "    description='GD type:',\n",
    "    disabled=False\n",
    ")\n",
    "    \n",
    "interact(GD_2D_nonlinear, a0=(-2,2,0.01), b0=(-2,2,0.01), alpha=(0,1,0.0001), n=(0,1000,1), m=(10,100,10), TheVariantFlag=radio_button_TheVariant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous implementation we used the following notation:\n",
    "- $n$: Number of iteration of Gradient Descent\n",
    "- Black dot: Solution $[a_n,b_n]$ at $n$-th step of the Gradient Descent.\n",
    "- Red-Yellow streamplot: Stream plot of the vector field generated by minus the Gradient of the error function $E(a,b)$\n",
    "- Blue-Green contour: Contour plot of the error function $E(a,b)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='acknowledgements' />\n",
    "\n",
    "# Acknowledgements\n",
    "[Back to TOC](#toc)\n",
    "* _Material created by professor Claudio Torres_ (`ctorres@inf.utfsm.cl`) DI UTFSM. November 2021.- v1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "state": {
    "7fd91d6f0d2545e7af10aae93cfe07e9": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
