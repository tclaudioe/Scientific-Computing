{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"http://sct.inf.utfsm.cl/wp-content/uploads/2020/04/logo_di.png\" style=\"width:60%\">\n",
    "    <h1> INF-285 - Computación Científica </h1>\n",
    "    <h2> An small but detailed example of GMRes </h2>\n",
    "    <h2> <a href=\"#acknowledgements\"> [S]cientific [C]omputing [T]eam </a> </h2>\n",
    "    <h2> Version: 1.00</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='toc' />\n",
    "\n",
    "## Table of Contents\n",
    "* [Preliminary: Short review of useful topics for this Jupyter Notebook](#preliminary)\n",
    "    * [Matrix vector product](#matvec)\n",
    "    * [A least-square problem](#prels)\n",
    "    * [Translating a linear system of equations to a least-square problem](#fromlstolsp)\n",
    "    * [How this is connected with GMRes](#connectiongmres)\n",
    "    * [What does GMRes do? What are its advantages and disadvantages?](#questionsprelim)\n",
    "* [The Small Example](#smallexample)\n",
    "* [The Krylov sub-space](#krylovsubspace)\n",
    "* [Arnoldi Iteration for the computation of the upper Hessenberg form](#arnoldi)\n",
    "* [Looking at the vectors obtained](#lookingatvectors)\n",
    "    * [First case: Krylov sub-space](#plotfirstcase)\n",
    "    * [Second case: Looking at the vectors using the orthonormal parametrization of x](#plotsecondcase)\n",
    "    * [Final case: Solving the small least-square problems](#plotfinalcase)\n",
    "* [Colorful version of GMRes](#colorfulgmres)\n",
    "    * [Matrix A0](#ma0)\n",
    "    * [Matrix A1](#ma1)\n",
    "    * [Matrix A2](#ma2)\n",
    "    * [Matrix A3](#ma3)\n",
    "    * [With a widget but lossing the colors..., nevertheless it is useful for looking at different values of m](#uncolorfulgmres)\n",
    "* [Acknowledgements](#acknowledgements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "from ipywidgets import interact # type: ignore\n",
    "import ipywidgets as widgets # type: ignore \n",
    "\n",
    "import matplotlib # type: ignore\n",
    "FS = 14\n",
    "matplotlib.rc('xtick', labelsize=FS)\n",
    "matplotlib.rc('ytick', labelsize=FS)\n",
    "plt.rcParams.update({\n",
    "    'font.size': FS,\n",
    "    'text.usetex': True,\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': 'Helvetica',\n",
    "    'text.latex.preamble': r'\\usepackage{amsfonts}\\usepackage{amsmath}'\n",
    "})\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "# https://pypi.org/project/colorama/\n",
    "# conda install -c anaconda colorama\n",
    "# Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n",
    "# Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n",
    "# Style: DIM, NORMAL, BRIGHT, RESET_ALL\n",
    "textBold = lambda x: Style.BRIGHT+x+Style.RESET_ALL\n",
    "textBoldH = lambda x: Style.BRIGHT+Back.YELLOW+x+Style.RESET_ALL\n",
    "textBoldI = lambda x: Style.BRIGHT+Back.GREEN+Fore.BLACK+x+Style.RESET_ALL\n",
    "textBoldR = lambda x: Style.BRIGHT+Back.RED+Fore.BLACK+x+Style.RESET_ALL\n",
    "\n",
    "def colorful_GMRes(A,b,m=3):\n",
    "\t# Checking it all make sense:\n",
    "\tif m>n:\n",
    "\t\traise UserWarning('ERROR: \"m\" must be less or equal than \"n\"')\n",
    "\n",
    "\t# Storing the initial residual norm\n",
    "\tnb=np.linalg.norm(b)\n",
    "\t# Pre-allocating the memory needed for the matrices Q and H\n",
    "\tQ = np.zeros((n,np.min([m+1,n])))\n",
    "\tH = np.zeros((np.min([m+1,n]),np.min([m,n])))\n",
    "\tflag_last_columns = False\n",
    "\tflag_break = False\n",
    "\n",
    "\t# Computing q1\n",
    "\tQ[:,0] = b / nb\n",
    "\t# Assuming we execute \"m\" iterations, where \"m<n\"\n",
    "\tfor k in np.arange(m):\n",
    "\t\tprint(textBoldI('Processing column '),textBold('k ='),textBold(str(k)))\n",
    "\t\t##############################\n",
    "\t\t# Arnoldi iteration\n",
    "\t\t##############################\n",
    "\t\t# Build the initial LHS of \"A@q_k=\\sum_{i=1}^{k+1} h_{i,k}*q_i\"\n",
    "\t\tif k<n-1:\n",
    "\t\t\t# THIS IS THE COMMON CASE\n",
    "\t\t\ty = np.dot(A, Q[:,k])\n",
    "\t\t\tfor j in np.arange(np.min([k+1,n])):\n",
    "\t\t\t\tH[j,k] = np.dot(Q[:,j], y)\n",
    "\t\t\t\ty = y - H[j,k]*Q[:,j]\n",
    "\t\t\tH[k+1,k] = np.linalg.norm(y)\n",
    "\t\t\t# We check if H[k+1,k] is not null, so we can build q_{k+1} \n",
    "\t\t\tif (np.abs(H[k+1,k]) > threshold):\n",
    "\t\t\t\t# No break-down -> we can get a new orthonormal vector\n",
    "\t\t\t\tQ[:,k+1] = y/H[k+1,k]\n",
    "\t\t\telse:\n",
    "\t\t\t\t# This is a 'good' break down!\n",
    "\t\t\t\tflag_break=True\n",
    "\t\telse: \n",
    "\t\t\t# When we get k=n-1, i.e. we need to process the last column,\n",
    "\t\t\t# the procedure only needs to compute the coefficients.\n",
    "\t\t\ty = np.dot(A, Q[:,k])\n",
    "\t\t\tfor j in np.arange(np.min([k+1,n])):\n",
    "\t\t\t\tH[j,k] = np.dot(Q[:,j], y)\n",
    "\t\t\t\ty = y - H[j,k]*Q[:,j]\n",
    "\t\t\tflag_last_columns=True\n",
    "\t\t##############################\n",
    "\t\n",
    "\t\t############################################################\n",
    "\t\t# Finding the approximation or 'exact' solution.\n",
    "\t\t############################################################\n",
    "\t\tif flag_last_columns:\n",
    "\t\t\t# Do you remember why we have \"e_1\" here?\n",
    "\t\t\te1 = np.zeros(n)        \n",
    "\t\t\te1[0]=1\n",
    "\t\t\tH_tilde = H\t\n",
    "\t\t\t# Solving the 'SMALL' \"SQUARE\" linear system of equations. \n",
    "\t\t\tck = np.linalg.solve(H_tilde, nb*e1)\n",
    "\t\t\txk = np.dot(Q[:,0:(k+1)], ck)\n",
    "\t\telif flag_break:\n",
    "\t\t\t# Early break_down (which is good!)\n",
    "\t\t\t# Do you remember why we have \"e_1\" here?\n",
    "\t\t\te1 = np.zeros(k+1)        \n",
    "\t\t\te1[0]=1\n",
    "\t\t\tH_tilde=H[0:(k+1),0:(k+1)]\n",
    "\t\t\tck = np.linalg.solve(H_tilde, nb*e1)\n",
    "\t\t\txk = np.dot(Q[:,0:(k+1)], ck)\n",
    "\t\t\tprint(' ',textBoldH('Reduced problem solved:'))\n",
    "\t\t\tprint('  ',textBold('H_tilde :\\n'),H_tilde)\n",
    "\t\t\tprint('  ',textBold('||b||*e_1 :'),nb*e1)\n",
    "\t\t\tprint('  ',textBold('ck:'),ck)\n",
    "\t\t\tprint('  ',textBoldH('||nb*e1-H_tilde@ck||\\t='),np.linalg.norm(nb*e1-H_tilde@ck))\n",
    "\t\t\tprint('  ',textBold('xk found:'),xk)\n",
    "\t\t\tprint('  ',textBoldH('||b-A@xk||\\t\\t='),np.linalg.norm(nb*e1-H_tilde@ck))\n",
    "\t\t\tprint(textBoldR('####################################################################################'))\n",
    "\t\t\tprint(textBoldI('GMRes finished in only '),textBold('%d'%(k+1)),textBoldI('iterations!!!'))\n",
    "\t\t\tprint(textBoldR('####################################################################################'))\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\t# THIS IS THE COMMON CASE\n",
    "\t\t\t# Do you remember why we have \"e_1\" here?\n",
    "\t\t\te1 = np.zeros((k+1)+1)        \n",
    "\t\t\te1[0]=1\n",
    "\t\t\tH_tilde=H[0:(k+1)+1,0:k+1]\n",
    "\t\t\t# Solving the 'SMALL' least square problem. \n",
    "\t\t\tck = np.linalg.lstsq(H_tilde, nb*e1,rcond=None)[0] \n",
    "\t\t\txk = np.dot(Q[:,0:(k+1)], ck)\n",
    "\t\tprint(' ',textBoldH('Reduced problem solved:'))\n",
    "\t\tprint('  ',textBold('H_tilde :\\n'),H_tilde)\n",
    "\t\tprint('  ',textBold('||b||*e_1 :'),nb*e1)\n",
    "\t\tprint('  ',textBold('ck:'),ck)\n",
    "\t\tprint('  ',textBoldH('||nb*e1-H_tilde@ck||\\t='),np.linalg.norm(nb*e1-H_tilde@ck))\n",
    "\t\tprint('  ',textBold('xk found:'),xk)\n",
    "\t\tprint('  ',textBoldH('||b-A@xk||\\t\\t='),np.linalg.norm(nb*e1-H_tilde@ck))\n",
    "\t\tif flag_last_columns:\n",
    "\t\t\tprint(textBoldR('####################################################################################'))\n",
    "\t\t\tprint(textBoldI('GMRes finished in '),textBold('3'),textBoldI('iterations.'))\n",
    "\t\t\tprint(textBoldR('####################################################################################'))\n",
    "\t############################################################\n",
    " \n",
    "\t# For comparison we include the np.linalg.solve approximation\n",
    "\tprint(textBoldH('\\nGMRes approximation\\t:'),xk)\n",
    "\tprint(textBoldH('np.linalg.solve\\t\\t:'),np.linalg.solve(A,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='preliminary' />\n",
    "\n",
    "# Preliminary: Short review of useful topics for this Jupyter Notebook\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='matvec' />\n",
    "\n",
    "## Matrix vector product\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "Consider that the matrix $A$ belong to $\\mathbb{R}^{m\\times m}$ and $\\mathbf{x}\\in\\mathbb{R}^m$.\n",
    "\n",
    "A matrix-vector product $A\\,\\mathbf{x}$ can be understood as a linear combination of the columns of $A$, say $\\mathbf{a}_i$ for $i\\in\\{1,2,3,\\dots,m\\}$, and the coefficients $x_i$, which are the components of $\\mathbf{x}$.\n",
    "Thus,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    A\\,\\mathbf{x} \n",
    "    &=\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{a}_1, & \\mathbf{a}_2, & \\mathbf{a}_3, & \\dots & \\mathbf{a}_m\n",
    "    \\end{bmatrix}\\,\\mathbf{x}\\\\\n",
    "    &=\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{a}_1, & \\mathbf{a}_2, & \\mathbf{a}_3, & \\dots & \\mathbf{a}_m\n",
    "    \\end{bmatrix}\\,\n",
    "    \\begin{bmatrix}\n",
    "        x_1\\\\\n",
    "        x_2\\\\\n",
    "        \\vdots\\\\\n",
    "        x_n\n",
    "    \\end{bmatrix}\\\\\n",
    "    &=\n",
    "    x_1\\,\\mathbf{a}_1+x_2\\,\\mathbf{a}_2+x_3\\,\\mathbf{a}_3 +\\dots+ x_n\\,\\mathbf{a}_m\\\\\n",
    "    &=\n",
    "    \\sum_{i=1}^m x_i\\,\\mathbf{a}_i.\n",
    "\\end{align*}\n",
    "$$\n",
    "This means that whenever we see $A\\,\\mathbf{x}$ we get a vector that has the form $\\sum_{i=1}^m x_i\\,\\mathbf{a}_i$.\n",
    "This will be useful for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='prels' />\n",
    "\n",
    "## A least-square problem\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "Consider that the matrix $A$ belong to $\\mathbb{R}^{m\\times n}$, $\\mathbf{x}\\in\\mathbb{R}^n$ and $\\mathbf{b}\\in\\mathbb{R}^m$.\n",
    "\n",
    "A least-square problem can be written in several forms.\n",
    "For instance, we traditionally write the residual vector $\\mathbf{r}=\\mathbf{b}-A\\,\\mathbf{x}$, where we write,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\overline{\\mathbf{x}} \n",
    "        &= \\argmin_{\\mathbf{x}\\in\\mathbb{R}^n} \\left\\| \\mathbf{r} \\right\\|_2^2\\\\\n",
    "        &= \\argmin_{\\mathbf{x}\\in\\mathbb{R}^n} \\left\\| \\mathbf{b}-A\\,\\mathbf{x} \\right\\|_2^2\\\\\n",
    "        &= \\argmin_{\\mathbf{x}\\in\\mathbb{R}^n} \\left\\| \\mathbf{b}-\\sum_{i=1}^n x_i\\,\\mathbf{a}_i \\right\\|_2^2.\n",
    "\\end{align*}\n",
    "$$\n",
    "Particularly the last form says that we want the find the coefficients $x_i$ of the linear combinations of the columns of the matrix $A$, i.e. $\\mathbf{a}_i$ to approximate $\\mathbf{b}$, such that we minimiza the 2-norm.\n",
    "This will be usefull again for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='fromlstolsp' />\n",
    "\n",
    "## Translating a linear system of equations to a least-square problem\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "Consider that the matrix $A$ belong to $\\mathbb{R}^{m\\times m}$ and is not singular, $\\mathbf{x}\\in\\mathbb{R}^n$, and $\\mathbf{b}\\in\\mathbb{R}^m$.\n",
    "\n",
    "First, we will make a connection between a linear system of equations and a least-square problem.\n",
    "For instance, we can still define $\\mathbf{r}=\\mathbf{b}-A\\,\\mathbf{x}$ for a linear system of equations.\n",
    "In this case, all the dimensions match, i.e. all the vectors involved are of dimension $m$ and the matrix $A$ is of dimension $m\\times m$.\n",
    "This implies that by solving the linear system of equations $A\\,\\mathbf{x}=\\mathbf{b}$ we can make the residual vector equal to the zero vector, i.e. $\\mathbf{0}$, just by replacing $\\mathbf{x}$ by $A^{-1}\\,\\mathbf{b}$ in the residual vector above.\n",
    "Recall that $A^{-1}$ exists (we usually don't want to compute but this does not mean it does not exists!), so when we replace it we get,\n",
    "$$\n",
    "\\begin{align*}\n",
    " \\mathbf{r}\n",
    "    &=\\mathbf{b}-A\\,\\mathbf{x}\\\\\n",
    "    &=\\mathbf{b}-A\\,A^{-1}\\,\\mathbf{b}\\\\\n",
    "    &=\\mathbf{b}-I\\,\\mathbf{b}\\\\\n",
    "    &=\\mathbf{b}-\\mathbf{b}\\\\\n",
    "    &=\\mathbf{0}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Now, let's suppose we **parametrize** or **restrict** the vector space where **we want** to _find_ an **approximation** of the _solution_ $\\mathbf{x}$.\n",
    "For instance, a possible **restriction** for the approximation of $\\mathbf{x}$ is the vector sub-space $V\\subset \\mathbb{R}^m$, where $V=\\mathrm{span}\\left(\\mathbf{v}_1,\\mathbf{v}_2,\\mathbf{v}_3\\right)$ and the vectors $\\mathbf{v}_j$ for $j\\in\\{1,2,3\\}$ are linearly independent.\n",
    "This implies that the dimension of $V$ is 3.\n",
    "\n",
    "So, **how we find the _\"best\"_ approximation in $V$?** \n",
    "Recall that here we consider the best approximation is in the **least-square** sense.\n",
    "Thus, we need to minimize the following expression,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\left.\\mathbf{x}^{\\textrm{best}}\\right|_{V}\n",
    "        &= \\argmin_{\\mathbf{x}\\in V} \\left\\| \\mathbf{b}-A\\,\\mathbf{x} \\right\\|_2^2,\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\left.\\mathbf{x}^{\\textrm{best}}\\right|_{V}$ denotes that we are restricting the vector $\\mathbf{x}^{\\textrm{best}}$ to $V$.\n",
    "The challenge here seems to be the _computation_ of the **minimization** problem but **restricting** the domain where $\\mathbf{x}$ belongs.\n",
    "Recall that in this problem $\\mathbf{x}$ is a vector with $m$ components, but when we restricted to the vectors sub-space $V$ the components ($x_i$) are not just reals numbers, there is a correlation between them.\n",
    "In summary, solving this problems that way is _cumbersome_.\n",
    "\n",
    "A better way to solve the previous minimization problem is by means a **parametrization** of the vector sub-space $V$.\n",
    "In particular, to assure that $\\mathbf{x}$ belongs to $V$ is by writing it as,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\left.\\mathbf{x}\\right|_{V} \n",
    "        &= c_1\\,\\mathbf{v}_1+c_2\\,\\mathbf{v}_2+c_3\\,\\mathbf{v}_3\\\\\n",
    "        &=\n",
    "        \\underbrace{\\begin{pmatrix}\n",
    "           \\mathbf{v}_1, & \\mathbf{v}_2, & \\mathbf{v}_3 \n",
    "        \\end{pmatrix}}_{\\displaystyle{\\textrm{This is a $m \\times 3$ matrix}}}\n",
    "        \\underbrace{\\begin{pmatrix}\n",
    "           c_1\\\\\n",
    "           c_2\\\\\n",
    "           c_3\n",
    "        \\end{pmatrix}\n",
    "        }_{\\displaystyle{\\textrm{This is a vector}}}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $c_j\\in \\mathbb{R}$ are unknown coefficients to be determined.\n",
    "Thus, using this, we can translate the previous minimization problem as follows,\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\min_{\\mathbf{x}\\in V} \\left\\| \\mathbf{b}-A\\,\\mathbf{x} \\right\\|_2^2\n",
    "    &=\n",
    "    \\min_{\\mathbf{c}\\in \\mathbb{R}^3} \\left\\| \\mathbf{b}-A\\,\\begin{pmatrix}\n",
    "            \\mathbf{v}_1, & \\mathbf{v}_2, & \\mathbf{v}_3 \n",
    "            \\end{pmatrix}\\,\\mathbf{c} \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{\\mathbf{c}\\in \\mathbb{R}^3} \\left\\| \\mathbf{b}-A\\,\\left(c_1\\,\\mathbf{v}_1+c_2\\,\\mathbf{v}_2+c_3\\,\\mathbf{v}_3\\right)\\right\\|_2^2\\nonumber\\\\\n",
    "    &=\n",
    "    \\min_{\\mathbf{c}\\in \\mathbb{R}^3} \\left\\| \\mathbf{b}\n",
    "        -c_1\\,\\underbrace{\\left(A\\,\\mathbf{v}_1\\right)}_{\\displaystyle{\\mathbf{w}_1}}\n",
    "        -c_2\\,\\underbrace{\\left(A\\,\\mathbf{v}_2\\right)}_{\\displaystyle{\\mathbf{w}_2}}\n",
    "        -c_3\\,\\underbrace{\\left(A\\,\\mathbf{v}_3\\right)}_{\\displaystyle{\\mathbf{w}_3}}\n",
    "        \\right\\|_2^2\n",
    "\\end{align}\n",
    "$$\n",
    "Some observations,\n",
    "1. Equation (1) shows how to translate a **restricted** minimization problem to a **traditional** least square problem, in this case for the unknown vector $\\mathbf{c}$, the RHS $\\mathbf{b}$, and the matrix $A\\,\\begin{pmatrix} \\mathbf{v}_1, & \\mathbf{v}_2, & \\mathbf{v}_3 \\end{pmatrix}\\in\\mathbb{R}^{m \\times 3}$. Note that the _matrix_ of the least-square problem is the product of two matrices.\n",
    "2. Equation (2) show that the minimization problem can be written as to find the coefficients $c_j$ of a linear combination of vectors $\\mathbf{w}_j$ that minimiza the corresponding residual.\n",
    "3. In the beginning of this sub-section we use the $\\argmin$ and at the end we used the $\\min$. The main difference is that the $\\argmin$ returns the solution vector where the minimum is found and $\\min$ return the value of the norm at the minimum. This is the reason why in Equation (1) were able to use equality, because the minimum values is the same. If we had used $\\argmin$ we would had had an inconsistency.\n",
    "4. An additional step is needed to find $\\left.\\mathbf{x}^{\\textrm{best}}\\right|_{V}$, this is solve as follows,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\overline{\\mathbf{c}}\n",
    "        &=\n",
    "        \\argmin_{\\mathbf{c}\\in \\mathbb{R}^3} \\left\\| \\mathbf{b}\n",
    "        -c_1\\,\\mathbf{w}_1\n",
    "        -c_2\\,\\mathbf{w}_2\n",
    "        -c_3\\,\\mathbf{w}_3\n",
    "        \\right\\|_2^2,\\\\\n",
    "    \\left.\\mathbf{x}^{\\textrm{best}}\\right|_{V}\n",
    "        &=\n",
    "        \\begin{pmatrix}\n",
    "            \\mathbf{v}_1, & \\mathbf{v}_2, & \\mathbf{v}_3 \n",
    "        \\end{pmatrix}\\,\\overline{\\mathbf{c}} = \\overline{c}_1\\,\\mathbf{v}_1+\\overline{c}_2\\,\\mathbf{v}_2+\\overline{c}_3\\,\\mathbf{v}_3.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='connectiongmres' />\n",
    "\n",
    "## How this is connected with GMRes\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "1. The **restricted** sub-space will be the Krylov sub-space $\\mathcal{K}_k=\\text{span}\\left(\\mathbf{b}, A\\,\\mathbf{b}, A^2\\,\\mathbf{b}, A^3\\,\\mathbf{b}, \\dots, A^{k-1}\\,\\mathbf{b}\\right)$.\n",
    "2. There will be a least-square problem that we need to solve, but thanks to the partial reduction of the matrix $A$ to the upper Hessenberg form $A\\,Q_k=Q_{k+1}\\,\\widetilde{H}_k$, we will be solving a very small least-square problem! **This is one of the great features of GMRes!**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='questionsprelim' />\n",
    "\n",
    "## What does GMRes do? What are its advantages and disadvantages?\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "**It solves square linear system of equations by means of a sequence of **small** least-square problems**.\n",
    "\n",
    "\n",
    "- Advantages\n",
    "    - It solves a square linear system of equations without _modifying_ or _accesing_ any of its coefficients, as matrix factorizations, such as $PALU$, do. **It only requires to compute, several times, the product between the matrix $A$ and a vector**.\n",
    "    - The amount of memory it uses is proportional to the number of iterations performed and a way to control this is to _restart_ GMRes, i.e. use the approximation found as a _initial guess_.\n",
    "    - Considering exact arithmetic, it finds the **exact** solution in at most $n$ steps for an $n\\times n$ matrix.\n",
    "    - It can find a **numerical solution** in less that $n$ iterations, this is called _breakdown_ and it is a good thing!\n",
    "- Disadvantages\n",
    "    - The memory required is proportional to number of iterations squared.\n",
    "    - It requires to solve a least-square problem, but _small_, per iteration.\n",
    "    - It may be challenging to understand but **it can help A LOT to solve linear system of equations that otherwise would require too much memory**. See for install the Jupyter Notebook _\"Bonus - 07 - Sylvester Equation with GMRes.ipynb\"_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='smallexample' />\n",
    "\n",
    "# The Small Example\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "We will analyze the use of GMRes for solving the following linear system of equations,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\begin{bmatrix}\n",
    "        1 & 2 & 3\\\\\n",
    "        3 & 2 & 1\\\\\n",
    "        1 & 1 & -1\n",
    "    \\end{bmatrix}\n",
    "    \\mathbf{x} &=\n",
    "    \\begin{bmatrix}\n",
    "        1\\\\\n",
    "        1\\\\\n",
    "        1\n",
    "    \\end{bmatrix}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[43mThe determinant of A\u001b[0m\n",
      "\u001b[1m|A|:\u001b[0m 8.000000000000002\n",
      "\u001b[1m\u001b[43mSince the determinant is not equal to 0, the linear system of equation has a unique solution.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,3],[3,2,1],[1,1,-1]])\n",
    "b = np.array([1,1,1])\n",
    "\n",
    "# We compute the determinant of A to make sure it is not singular.\n",
    "print(textBoldH('The determinant of A'))\n",
    "print(textBold('|A|:'),np.linalg.det(A))\n",
    "print(textBoldH('Since the determinant is not equal to 0, the linear system of equation has a unique solution.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='krylovsubspace' />\n",
    "\n",
    "# The Krylov sub-space\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "Now we will build the _original_ Krylov sub-spaces, for completeness, we will show the three sub-spaces,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathcal{K}_1&=\\textrm{span}\\left(\\mathbf{b}\\right)\\subset \\mathcal{K}_2,\\\\\n",
    "    \\mathcal{K}_2&=\\textrm{span}\\left(\\mathbf{b}, A\\,\\mathbf{b}\\right) \\subset \\mathcal{K}_3, \\\\\n",
    "    \\mathcal{K}_3&=\\textrm{span}\\left(\\mathbf{b}, A\\,\\mathbf{b}, A^2\\,\\mathbf{b}\\right) = \\mathbb{R}^3.\n",
    "\\end{align*}\n",
    "$$\n",
    "Notice that we only need 3 terms since we are solving a linear square of equations with a matrix of dimension $3\\times 3$.\n",
    "\n",
    "Recall that, in general, we have 3 equivalent Krylov sub-spaces,\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{K}_k\n",
    "&=\\text{span}\\left(\\mathbf{b}, A\\,\\mathbf{b}, A^2\\,\\mathbf{b}, A^3\\,\\mathbf{b}, \\dots, A^{k-1}\\,\\mathbf{b}\\right)\\\\\n",
    "&=\\text{span}\\left(\\mathbf{q}_1, \\mathbf{q}_2, \\mathbf{q}_3, \\mathbf{q}_4, \\dots, \\mathbf{q}_k\\right)\\\\\n",
    "&= \\text{span}\\left(\\mathbf{q}_1, A\\,\\mathbf{q}_1, A\\,\\mathbf{q}_2, A\\,\\mathbf{q}_3, \\dots, A\\,\\mathbf{q}_{k-1}\\right).\n",
    "\\end{align*}$$\n",
    "\n",
    "In the following, we will be using the relationship between the **second** and **third** representations.\n",
    "See the classnotes for more details, here we will go directly into the computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[43mShowing the computed basis vectors as ROW vectors:\u001b[0m\n",
      "\u001b[1mK[:,0]:\u001b[0m [1. 1. 1.]\n",
      "\u001b[1mK[:,1]:\u001b[0m [6. 6. 1.]\n",
      "\u001b[1mK[:,2]:\u001b[0m [21. 31. 11.]\n",
      "\u001b[1m\u001b[43mDeterminant of K to show it contains linearly-independent columns if it is not null:\u001b[0m\n",
      "\u001b[1m|K|:\u001b[0m 50.000000000000014\n",
      "\u001b[1m\u001b[43mShowing the matrix K, where the columns are the basis vectors:\u001b[0m\n",
      "\u001b[1mK:\n",
      "\u001b[0m [[ 1.  6. 21.]\n",
      " [ 1.  6. 31.]\n",
      " [ 1.  1. 11.]]\n"
     ]
    }
   ],
   "source": [
    "# Storing the Krylov _original_ basis:\n",
    "K = np.zeros((3,3))\n",
    "K[:,0] = b              # b\n",
    "K[:,1] = A @ b          # A @ b\n",
    "K[:,2] = A @ (A @ b)    # A^2 @ b\n",
    "\n",
    "print(textBoldH('Showing the computed basis vectors as ROW vectors:'))\n",
    "print(textBold('K[:,0]:'),K[:,0])\n",
    "print(textBold('K[:,1]:'),K[:,1])\n",
    "print(textBold('K[:,2]:'),K[:,2])\n",
    "\n",
    "print(textBoldH('Determinant of K to show it contains linearly-independent columns if it is not null:'))\n",
    "print(textBold('|K|:'),np.linalg.det(K))\n",
    "\n",
    "print(textBoldH('Showing the matrix K, where the columns are the basis vectors:'))\n",
    "print(textBold('K:\\n'),K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='arnoldi' />\n",
    "\n",
    "# Arnoldi Iteration for the computation of the upper Hessenberg form\n",
    "[Back to TOC](#toc) \n",
    "\n",
    "Here we will use the _Arnoldi iteration_ (i.e. Modified Gram-Schmidt algorithm) for the orthonormalization of the columns of $K$.\n",
    "In particular, we will compute the orthonormal vectors $\\mathbf{q}_1$, $\\mathbf{q}_2$, $\\mathbf{q}_3$, and the matrix $\\widetilde{H}_k$, from the following set of equations,\n",
    "$$\n",
    "\\begin{align}\n",
    "\tA\\,\\mathbf{q}_1 &= h_{11}\\,\\mathbf{q}_1+h_{21}\\,\\mathbf{q}_2,\\\\\n",
    "\tA\\,\\mathbf{q}_2 &= h_{12}\\,\\mathbf{q}_1+h_{22}\\,\\mathbf{q}_2+h_{32}\\,\\mathbf{q}_3,\\\\\n",
    "\tA\\,\\mathbf{q}_3 &= h_{13}\\,\\mathbf{q}_1+h_{23}\\,\\mathbf{q}_2+h_{33}\\,\\mathbf{q}_3,\n",
    "\\end{align}\n",
    "$$\n",
    "where we start from knowing that $\\mathbf{q}_1=\\dfrac{\\mathbf{b}}{\\|\\mathbf{b}\\|}$.\n",
    "So, we first compute $\\mathbf{q}_1$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocating the memory to store Q and H\n",
    "Q = np.zeros((3,3))\n",
    "H = np.zeros((3,3))\n",
    "\n",
    "# q1 = b/||b||\n",
    "q1 = b/np.linalg.norm(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the next step is to compute the $\\textrm{\\color{red}unknown}$ terms from **Equation (1)**, which are the terms in $\\textrm{\\color{red}red}$ and the $\\textrm{\\color{blue}known}$ terms are in $\\textrm{\\color{blue}blue}$,\n",
    "$$\n",
    "{\\color{blue} A\\,\\mathbf{q}_1} = {\\color{red} h_{11}}\\,{\\color{blue} \\mathbf{q}_1}+{\\color{red}h_{21}\\,\\mathbf{q}_2}.\n",
    "$$\n",
    "The following code computes the $\\textrm{\\color{red}unknown}$ terms using the unrolled Arnoldi iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShowing the coefficients obtained:\u001b[0m\n",
      "[h11,h21]: [4.333333333333334, 2.357022603955159]\n",
      "\u001b[1mShowing that equality is numerically satisfied:\u001b[0m\n",
      "A@q1-(h11*q1+h21*q2): [0.00000000e+00 0.00000000e+00 1.11022302e-16]\n"
     ]
    }
   ],
   "source": [
    "# A@q1 = h11*q1+h21*q2\n",
    "y = A@q1\n",
    "h11 = np.dot(q1,y)\n",
    "y -= h11*q1\n",
    "h21 = np.linalg.norm(y)\n",
    "q2 = y/h21\n",
    "print(textBold('Showing the coefficients obtained:'))\n",
    "print('[h11,h21]:',[h11,h21])\n",
    "print(textBold('Showing that equality is numerically satisfied:'))\n",
    "print('A@q1-(h11*q1+h21*q2):',A@q1-(h11*q1+h21*q2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will work on **Equation (2)**, which is,\n",
    "$$\n",
    "{\\color{blue} A\\,\\mathbf{q}_2} = \n",
    "    {\\color{red} h_{12}}\\,{\\color{blue} \\mathbf{q}_1}\n",
    "    +\n",
    "    {\\color{red} h_{22}}\\,{\\color{blue} \\mathbf{q}_2}\n",
    "    +{\\color{red}h_{32}\\,\\mathbf{q}_2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShowing the coefficients obtained:\u001b[0m\n",
      "[h12,h22,h32]: [0.9428090415820628, -1.333333333333334, 1.7320508075688772]\n",
      "\u001b[1mShowing that equality is numerically satisfied:\u001b[0m\n",
      "A@q2-(h12*q1+h22*q2+h32*q3): [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# A@q2 = h12*q1+h22*q2+h32*q3\n",
    "y = A@q2\n",
    "h12 = np.dot(q1,y)\n",
    "y -= h12*q1\n",
    "h22 = np.dot(q2,y)\n",
    "y -= h22*q2\n",
    "h32 = np.linalg.norm(y)\n",
    "q3 = y/h32\n",
    "print(textBold('Showing the coefficients obtained:'))\n",
    "print('[h12,h22,h32]:',[h12,h22,h32])\n",
    "print(textBold('Showing that equality is numerically satisfied:'))\n",
    "print('A@q2-(h12*q1+h22*q2+h32*q3):',A@q2-(h12*q1+h22*q2+h32*q3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will work on **Equation (3)**, which is,\n",
    "$$\n",
    "{\\color{blue} A\\,\\mathbf{q}_3} = \n",
    "    {\\color{red} h_{13}}\\,{\\color{blue} \\mathbf{q}_1}\n",
    "    +\n",
    "    {\\color{red} h_{23}}\\,{\\color{blue} \\mathbf{q}_2}\n",
    "    +\n",
    "    {\\color{red} h_{33}}\\,{\\color{blue} \\mathbf{q}_3}.\n",
    "$$\n",
    "This case is a bit _different_ from the previous ones. \n",
    "The main difference is that the last term now has a $\\textrm{\\color{blue}known}$ part, which is ${\\color{blue} \\mathbf{q}_3}$.\n",
    "This implies that the procedure to find ${\\color{red} h_{33}}$ needs to be different to the one we used for the _last_ terms before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShowing the coefficients obtained:\u001b[0m\n",
      "[h13,h23,h33]: [-1.6626775227096734e-15, -7.415643429738541e-16, -1.0]\n",
      "\u001b[1mShowing that equality is numerically satisfied:\u001b[0m\n",
      "A@q3-(h13*q1+h23*q2+h33*q3): [-4.44089210e-16 -2.22044605e-16 -8.96266451e-17]\n",
      "\u001b[1m\u001b[43mFor completeness, we show the output for h33 when using:\n",
      " the norm and a dot product with q3\u001b[0m\n",
      "\u001b[1mh33=np.dot(q3,y)=\u001b[0m -1.0 \u001b[1m\u001b[42m\u001b[30m, which is the CORRECT procedure for this case.\u001b[0m\n",
      "\u001b[1mh33=||y||=\u001b[0m 0.9999999999999999 \u001b[1m\u001b[41m\u001b[30m, which is the INCORRECT procedure for this case.\u001b[0m \u001b[1m\u001b[43mThe magnitude is correct but the sign is wrong.\u001b[0m\n",
      "\u001b[1m\n",
      "Note that if we use the INCORRECT value for h33 the previous equality does not hold\u001b[0m\n",
      "A@q3-(h13*q1+h23*q2+h33_INCORRECT*q3): [ 1.41421356e+00 -1.41421356e+00  4.23163405e-16]\n"
     ]
    }
   ],
   "source": [
    "# A*q3 = h13*q1+h23*q2+h33*q3\n",
    "y = A@q3\n",
    "h13 = np.dot(q1,y)\n",
    "y -= h13*q1\n",
    "h23 = np.dot(q2,y)\n",
    "y -= h23*q2\n",
    "# IMPORTANT: Why can't we do this? Because we already have q3!\n",
    "# h33 = np.linalg.norm(y)\n",
    "# q3 = y/h33\n",
    "h33 = np.dot(q3,y)\n",
    "print(textBold('Showing the coefficients obtained:'))\n",
    "print('[h13,h23,h33]:',[h13,h23,h33])\n",
    "print(textBold('Showing that equality is numerically satisfied:'))\n",
    "print('A@q3-(h13*q1+h23*q2+h33*q3):',A@q3-(h13*q1+h23*q2+h33*q3))\n",
    "\n",
    "print(textBoldH('For completeness, we show the output for h33 when using:\\n the norm and a dot product with q3'))\n",
    "print(textBold('h33=np.dot(q3,y)='),h33, textBoldI(', which is the CORRECT procedure for this case.'))\n",
    "print(textBold('h33=||y||='),np.linalg.norm(y), textBoldR(', which is the INCORRECT procedure for this case.'),textBoldH('The magnitude is correct but the sign is wrong.'))\n",
    "print(textBold('\\nNote that if we use the INCORRECT value for h33 the previous equality does not hold'))\n",
    "print('A@q3-(h13*q1+h23*q2+h33_INCORRECT*q3):',A@q3-(h13*q1+h23*q2+np.linalg.norm(y)*q3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can show the matrix $Q_3$ and $H_3$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\n",
      " [[ 4.33333333e+00  9.42809042e-01 -1.66267752e-15]\n",
      " [ 2.35702260e+00 -1.33333333e+00 -7.41564343e-16]\n",
      " [ 0.00000000e+00  1.73205081e+00 -1.00000000e+00]]\n",
      "Q:\n",
      " [[ 5.77350269e-01  4.08248290e-01 -7.07106781e-01]\n",
      " [ 5.77350269e-01  4.08248290e-01  7.07106781e-01]\n",
      " [ 5.77350269e-01 -8.16496581e-01 -2.56395025e-16]]\n"
     ]
    }
   ],
   "source": [
    "Q[:,0] = q1\n",
    "Q[:,1] = q2\n",
    "Q[:,2] = q3\n",
    "\n",
    "H = np.array([[h11,h12,h13],[h21,h22,h23],[0,h32,h33]])\n",
    "\n",
    "print('H:\\n',H)\n",
    "print('Q:\\n',Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can show that the upper Hessenberg form $A\\,Q_3=Q_3\\,\\widetilde{H}_3$ is safiesfied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShowing the LHS of the upper Hessenberg form:\u001b[0m\n",
      "A@Q: [[ 3.46410162e+00 -1.22474487e+00  7.07106781e-01]\n",
      " [ 3.46410162e+00  1.22474487e+00 -7.07106781e-01]\n",
      " [ 5.77350269e-01  1.63299316e+00 -1.87694185e-16]]\n",
      "\u001b[1mShowing the RHS of the upper Hessenberg form:\u001b[0m\n",
      "Q@H: [[ 3.46410162e+00 -1.22474487e+00  7.07106781e-01]\n",
      " [ 3.46410162e+00  1.22474487e+00 -7.07106781e-01]\n",
      " [ 5.77350269e-01  1.63299316e+00 -9.80675399e-17]]\n",
      "\u001b[1mComputing the difference between the LHS and RHS.\u001b[0m \u001b[1m\u001b[43mIt should be the null matrix.\u001b[0m\n",
      "(A@Q)-(Q@H): [[ 0.00000000e+00  0.00000000e+00 -4.44089210e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.22044605e-16]\n",
      " [ 2.22044605e-16  0.00000000e+00 -8.96266451e-17]]\n",
      "\u001b[1m\u001b[42m\u001b[30mIt is the null matrix!\u001b[0m\n",
      "\u001b[1mComputing the matrix norm of the diference between the LHS and RHS.\u001b[0m \u001b[1m\u001b[43mIt should be 0 or close to 0.\u001b[0m\n",
      "5.512311447771244e-16\n",
      "\u001b[1m\u001b[42m\u001b[30mIt is close to 0!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(textBold('Showing the LHS of the upper Hessenberg form:'))\n",
    "print('A@Q:',(A@Q))\n",
    "print(textBold('Showing the RHS of the upper Hessenberg form:'))\n",
    "print('Q@H:',(Q@H))\n",
    "print(textBold('Computing the difference between the LHS and RHS.'),textBoldH('It should be the null matrix.'))\n",
    "print('(A@Q)-(Q@H):',(A@Q)-(Q@H))\n",
    "print(textBoldI('It is the null matrix!'))\n",
    "print(textBold('Computing the matrix norm of the diference between the LHS and RHS.'),textBoldH('It should be 0 or close to 0.'))\n",
    "print(np.linalg.norm(A@Q-Q@H))\n",
    "print(textBoldI('It is close to 0!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='lookingatvectors' />\n",
    "\n",
    "# Looking at the vectors obtained\n",
    "[Back to TOC](#toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='plotfirstcase' />\n",
    "\n",
    "## First case: Krylov sub-space\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "In this section we will show the basis of the Krylov sub-space.\n",
    "Notice that in the plot we normalize the vectors just to avoid visulization issues, this does not change the purpose since it does not change the direction of each vector.\n",
    "$$\n",
    "\\begin{align*}\n",
    "    K &= \\begin{bmatrix} \\mathbf{b}, & A\\,\\mathbf{b}, & A^2\\,\\mathbf{b} \\end{bmatrix},\\\\\n",
    "    Q &= \\begin{bmatrix} \\mathbf{q}_1, & \\mathbf{q}_2, & \\mathbf{q_3} \\end{bmatrix}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454c516cf5e64c1fb962a3500344f4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='elev', max=360), IntSlider(value=18, description='azim'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_vectors1(elev=15, azim=18, roll=0, show_Ki=True, show_qi=False, Ki=1, qi=1)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_vectors1(elev=15, azim=18, roll=0,show_Ki=True,show_qi=False,Ki=1,qi=1):\n",
    "    ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "    # Make the direction data for the arrows\n",
    "    n = 6\n",
    "    V = np.zeros((n,3))\n",
    "    # Normalizing for simplicity, but this does not change the length.\n",
    "    V[0,:] = K[:,0]/np.linalg.norm(K[:,0])\n",
    "    V[1,:] = K[:,1]/np.linalg.norm(K[:,1])\n",
    "    V[2,:] = K[:,2]/np.linalg.norm(K[:,2])\n",
    "\n",
    "    V[0+3,:] = q1\n",
    "    V[1+3,:] = q2\n",
    "    V[2+3,:] = q3\n",
    "    \n",
    "    if show_Ki and show_qi:\n",
    "        l=0\n",
    "        ax.quiver(0, 0, 0, V[l,0], V[l,1], V[l,2], length=1, normalize=True, color='red',alpha=0.5)\n",
    "        ax.quiver(0, 0, 0, V[3+l,0], V[3+l,1], V[3+l,2], length=1, normalize=True, color='black',alpha=0.5)\n",
    "        ax.text(V[l,0], V[l,1], V[l,2], r'$\\mathbf{K}_1=\\textbf{q}_1$',(1,1,0))\n",
    "        i = Ki\n",
    "        for l in np.arange(1,i):\n",
    "            ax.quiver(0, 0, 0, V[l,0], V[l,1], V[l,2], length=1, normalize=True, color='red',alpha=0.5)\n",
    "            ax.text(V[l,0], V[l,1], V[l,2], r'$\\mathbf{K}_{%d}$'%(l+1),(1,1,0)) \n",
    "        j = qi\n",
    "        for l in np.arange(1,j):\n",
    "            ax.quiver(0, 0, 0, V[3+l,0], V[3+l,1], V[3+l,2], length=1, normalize=True, color='black',alpha=0.5)\n",
    "            ax.text(V[3+l,0], V[3+l,1], V[3+l,2], r'$\\mathbf{q}_{%d}$'%(l+1),(1,1,0))\n",
    "    else:\n",
    "        if show_Ki:\n",
    "            i = Ki\n",
    "            for l in np.arange(i):\n",
    "                ax.quiver(0, 0, 0, V[l,0], V[l,1], V[l,2], length=1, normalize=True, color='red',alpha=0.5)\n",
    "                ax.text(V[l,0], V[l,1], V[l,2], r'$\\mathbf{K}_{%d}$'%(l+1),(1,1,0))\n",
    "        if show_qi:\n",
    "            j = qi\n",
    "            for l in np.range(j):\n",
    "                # ax.quiver(X[3:(3+j),0], X[3:(3+j),1], X[3:(3+j),2], V[3:(3+j),0], V[3:(3+j),1], V[3:(3+j),2], length=0.1, normalize=True,color='black',alpha=0.5)\n",
    "                ax.quiver(0, 0, 0, V[3+l,0], V[3+l,1], V[3+l,2], length=1, normalize=True, color='black',alpha=0.5)\n",
    "                ax.text(V[3+l,0], V[3+l,1], V[3+l,2], r'$\\mathbf{q}_{%d}$'%(l+1),(1,1,0))\n",
    "    \n",
    "    ax.view_init(elev, azim, roll)\n",
    "    ax.set_xlabel(r'$x_1$')\n",
    "    ax.set_ylabel(r'$x_2$')\n",
    "    ax.set_zlabel(r'$x_3$')\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_zlim(-1, 1)\n",
    "    plt.title(r'Krylov sub-space: $K_i=A^{i-1}\\,\\mathbf{b}$ (red) and $\\mathbf{q}_i$ (black)')\n",
    "    plt.show()\n",
    "    \n",
    "interact(show_vectors1,elev=(0,360,1),azim=(0,360,1),roll=(0,360,1),Ki=(1,3,1),qi=(1,3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='plotsecondcase' />\n",
    "\n",
    "## Second case: Looking at the vectors using the orthonormal parametrization of $\\mathbf{x}$\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "In the Preliminary section we show how to connect the solution of a linear system of equations with a least-square problem.\n",
    "Here, we will show a pre-GMRes analysis.\n",
    "We will consider as the vector space $V$, described before, the Krylov sub-space $\\mathcal{K}_3=\\text{span}\\left(\\mathbf{b}, A\\,\\mathbf{b}, A^2\\,\\mathbf{b}\\right)$.\n",
    "Thus, if we consider that the vectors $\\mathbf{q}_1$, $\\mathbf{q}_2$, and $\\mathbf{q}_3$, as a basis for $\\mathcal{K}_3$, the least-square minimization $ \\min_{\\mathbf{x}\\in \\mathcal{K}_3} \\left\\| \\mathbf{b}-A\\,\\mathbf{x} \\right\\|_2^2$ can be written as,\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\min_{\\mathbf{x}\\in \\mathcal{K}_3} \\left\\| \\mathbf{b}-A\\,\\mathbf{x} \\right\\|_2^2\n",
    "    &=\n",
    "    \\min_{\\mathbf{c}\\in \\mathbb{R}^3} \\left\\| \\mathbf{b}\n",
    "        -A\\,\\left(c_1\\,\\mathbf{q}_1+c_2\\,\\mathbf{q}_2+c_3\\,\\mathbf{q}_3\\right)\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{\\mathbf{c}\\in \\mathbb{R}^3} \\left\\| \\mathbf{b}\n",
    "        -c_1\\,\\left(A\\,\\mathbf{q}_1\\right)\n",
    "        -c_2\\,\\left(A\\,\\mathbf{q}_2\\right)\n",
    "        -c_3\\,\\left(A\\,\\mathbf{q}_3\\right)\n",
    "        \\right\\|_2^2.\n",
    "\\end{align}\n",
    "$$\n",
    "So, the following plot shows how well can the vector $\\mathbf{b}$ be approximated with the linear combination of the **vectors** $A\\,\\mathbf{q}_1$, $A\\,\\mathbf{q}_2$, and $A\\,\\mathbf{q}_3$.\n",
    "\n",
    "Note that the interesting part is when we find the numerical solution when using $\\mathcal{K}_1$ or $\\mathcal{K}_2$ in this case.\n",
    "For $\\mathcal{K}_3$, we actually recover $\\mathbb{R}^3$, so it is clear we will find the numerical solution.\n",
    "\n",
    "Thus, when you analyze the plot below consider we are looking to the $\\textrm{span}$ of the vectors shown.\n",
    "- This means that when you show only one vector, i.e. $A\\,\\textbf{q}_1$ the $\\textrm{span}$ is the line generated by that vector. So we are looking for the orthogonal projection of $\\mathbf{b}$ along $A\\,\\textbf{q}_1$. \n",
    "- Then, if you show $A\\,\\textbf{q}_1$ and $A\\,\\textbf{q}_2$, it means you will be looking for a solution which is the orthogonal projection of $\\mathbf{b}$ on the $\\textrm{span}(A\\,\\textbf{q}_1,A\\,\\textbf{q}_2)$.\n",
    "- For the last case, we have three linearly independent vectors, so we recover $\\mathbb{R}^3$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcb927914624bd7b367a6bf4101e683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='elev', max=360), IntSlider(value=18, description='azim'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_vectors2(elev=15, azim=18, roll=0, flag_Aq=False, Aq_i=1)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_vectors2(elev=15, azim=18, roll=0, flag_Aq=False, Aq_i=1):\n",
    "    ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "    # Make the direction data for the arrows\n",
    "    n = 4\n",
    "    V = np.zeros((n,3))\n",
    "\n",
    "    V[0,:] = A@q1/np.linalg.norm(A@q1)\n",
    "    V[1,:] = A@q2/np.linalg.norm(A@q2)\n",
    "    V[2,:] = A@q3/np.linalg.norm(A@q3)\n",
    "\n",
    "    V[0+3,:] = b\n",
    "\n",
    "    if flag_Aq:\n",
    "        i = Aq_i        \n",
    "        for j in np.arange(i):\n",
    "            ax.quiver(0, 0, 0, V[j,0], V[j,1], V[j,2], length=1, normalize=True,color='blue',alpha=0.5)\n",
    "            ax.text(V[j,0], V[j,1], V[j,2], r'$A\\,\\mathbf{q}_{%d}$'%(j+1),(1,1,0))\n",
    "    ax.quiver(0, 0, 0, V[3,0], V[3,1], V[3,2], color='green',alpha=0.5)\n",
    "    ax.text(V[3,0], V[3,1], V[3,2], r'$\\mathbf{b}$',(1,1,0))\n",
    "    \n",
    "    ax.view_init(elev, azim, roll)\n",
    "    ax.set_xlabel(r'$x_1$')\n",
    "    ax.set_ylabel(r'$x_2$')\n",
    "    ax.set_zlabel(r'$x_3$')\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_zlim(-1, 1)\n",
    "    \n",
    "    plt.title(r'Showing $A\\,\\mathbf{q}_i$ and $\\mathbf{b}$')\n",
    "    plt.show()\n",
    "    \n",
    "interact(show_vectors2,elev=(0,360,1),azim=(0,360,1),roll=(0,360,1),Aq_i=(1,3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='plotfinalcase' />\n",
    "\n",
    "## Final case: Solving the small least-square problems\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "**See more details in the classnotes! Here we show a _brief_ review.**\n",
    "\n",
    "For the final case, we will make use of the upper Hessenberg factorizations A\\,Q_k=Q_{k+1}\\,\\widetilde{H}_k$, the use depends on the value of $k$ because we will be getting a different least-square problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For $k=1$ we use the identity $A\\,\\mathbf{q}_1=Q_2\\,\\widetilde{H}_1$ and we consider $\\mathbf{x}\\in\\mathcal{K}_1$ can be parametrized by $c_1\\,\\mathbf{q}_1$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_{\\mathbf{x}\\in \\mathcal{K}_1} \\left\\| \\mathbf{b}-A\\,\\mathbf{x} \\right\\|_2^2\n",
    "    &=\n",
    "    \\min_{c_1\\in \\mathbb{R}} \\left\\| \\mathbf{b}\n",
    "        -A\\,\\left(c_1\\,\\mathbf{q}_1+\\right)\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{c_1\\in \\mathbb{R}} \\left\\| \\mathbf{b}\n",
    "        -A\\,\\mathbf{q}_1\\,c_1\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{c_1\\in \\mathbb{R}} \\left\\| \\mathbf{b}\n",
    "        -Q_2\\,\\widetilde{H}_1\\,c_1\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{c_1\\in \\mathbb{R}} \\left\\| \\begin{bmatrix} \\|\\mathbf{b}\\|\\\\ 0\\end{bmatrix}\n",
    "        -\\widetilde{H}_1\\,c_1\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{c_1\\in \\mathbb{R}} \\left\\| \\begin{bmatrix} \\|\\mathbf{b}\\|\\\\ 0\\end{bmatrix}\n",
    "        -\\begin{bmatrix} h_{1,1} \\\\ h_{2,1}\\end{bmatrix}\\,c_1\n",
    "        \\right\\|_2^2\\\\\n",
    "\\end{align*}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For $k=2$ we use the identity $A\\,Q_2=Q_3\\,\\widetilde{H}_2$ and we consider $\\mathbf{x}\\in\\mathcal{K}_2$ can be parametrized by $Q_2\\,\\begin{bmatrix} c_1 \\\\ c_2\\end{bmatrix}$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_{\\mathbf{x}\\in \\mathcal{K}_2} \\left\\| \\mathbf{b}-A\\,\\mathbf{x} \\right\\|_2^2\n",
    "    &=\n",
    "    \\min_{c\\in \\mathbb{R}^2} \\left\\| \\mathbf{b}\n",
    "        -A\\,Q_2\\,\\begin{bmatrix} c_1 \\\\ c_2\\end{bmatrix}\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{c\\in \\mathbb{R}^2} \\left\\| \\mathbf{b}\n",
    "        -Q_3\\,\\widetilde{H}_2\\,\\begin{bmatrix} c_1 \\\\ c_2\\end{bmatrix}\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{c\\in \\mathbb{R}^2} \\left\\| \\begin{bmatrix} \\|\\mathbf{b}\\|\\\\ 0 \\\\ 0 \\end{bmatrix}\n",
    "        -\\widetilde{H}_2\\,\\begin{bmatrix} c_1 \\\\ c_2\\end{bmatrix}\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{c\\in \\mathbb{R}^2} \\left\\| \\begin{bmatrix} \\|\\mathbf{b}\\|\\\\ 0 \\\\ 0 \\end{bmatrix}\n",
    "        -\\begin{bmatrix} h_{1,1} & h_{1,2}\\\\ h_{2,1} & h_{2,2} \\\\ 0 & h_{3,2} \\end{bmatrix}\\,\n",
    "        \\begin{bmatrix} c_1 \\\\ c_2\\end{bmatrix}\n",
    "        \\right\\|_2^2\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For $k=3$ we use the identity $A\\,Q_3=Q_3\\,\\widetilde{H}_3$ and we consider $\\mathbf{x}\\in\\mathcal{K}_3$ can be parametrized by $Q_3\\,\\begin{bmatrix} c_1 \\\\ c_2 \\\\ c_3\\end{bmatrix}$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_{\\mathbf{x}\\in \\mathcal{K}_3} \\left\\| \\mathbf{b}-A\\,\\mathbf{x} \\right\\|_2^2\n",
    "    &=\n",
    "    \\min_{c\\in \\mathbb{R}^3} \\left\\| \\mathbf{b}\n",
    "        -A\\,Q_3\\,\\begin{bmatrix} c_1 \\\\ c_2 \\\\ c_3\\end{bmatrix}\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{c\\in \\mathbb{R}^3} \\left\\| \\mathbf{b}\n",
    "        -Q_3\\,\\widetilde{H}_3\\,\\begin{bmatrix} c_1 \\\\ c_2 \\\\ c_3\\end{bmatrix}\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{c\\in \\mathbb{R}^3} \\left\\| \\begin{bmatrix} \\|\\mathbf{b}\\|\\\\ 0 \\\\ 0 \\end{bmatrix}\n",
    "        -\\widetilde{H}_3\\,\\begin{bmatrix} c_1 \\\\ c_2 \\\\ c_3\\end{bmatrix}\n",
    "        \\right\\|_2^2\\\\\n",
    "    &=\n",
    "    \\min_{c\\in \\mathbb{R}^3} \\left\\| \\begin{bmatrix} \\|\\mathbf{b}\\|\\\\ 0 \\\\ 0 \\end{bmatrix}\n",
    "        -\\begin{bmatrix} h_{1,1} & h_{1,2} & h_{1,3}\\\\ h_{2,1} & h_{2,2} & h_{2,3} \\\\ 0 & h_{3,2} & h_{3,3} \\end{bmatrix}\\,\n",
    "        \\begin{bmatrix} c_1 \\\\ c_2 \\\\ c_3\\end{bmatrix}\n",
    "        \\right\\|_2^2\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, for $k=1$ and $k=2$ we get 2 least-square problems, and for $k=3$, it is just a linear system of equations.\n",
    "To better understand the small least-square problem, we will plot what it is minimizes.\n",
    "\n",
    "For simplicity of notation in the plot we define the following vectors:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\widetilde{\\mathbf{b}}_2 &= \\begin{bmatrix} \\|\\mathbf{b}\\| & 0\\end{bmatrix}^\\top,\\\\\n",
    "    \\widetilde{\\mathbf{b}}_3 &= \\begin{bmatrix} \\|\\mathbf{b}\\| & 0 & 0\\end{bmatrix}^\\top,\\\\\n",
    "    \\widetilde{\\mathbf{h}}_1 &= \\begin{bmatrix} h_{1,1} & h_{2,1}\\end{bmatrix}^\\top,\\\\\n",
    "    \\mathbf{h}_1 &= \\begin{bmatrix} h_{1,1} & h_{2,1} & 0\\end{bmatrix}^\\top,\\\\\n",
    "    \\mathbf{h}_2 &= \\begin{bmatrix} h_{1,2} & h_{2,2} & h_{3,2}\\end{bmatrix}^\\top,\\\\\n",
    "    \\mathbf{h}_3 &= \\begin{bmatrix} h_{1,3} & h_{2,3} & h_{3,3}\\end{bmatrix}^\\top.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd05d29367f4c72af328007e19e249a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='elev', max=360), IntSlider(value=18, description='azim'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_vectors3(elev=15, azim=18, roll=0, k=1)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_vectors3(elev=15, azim=18, roll=0, k=1):\n",
    "\n",
    "    if k==1:\n",
    "        fig, ax = plt.subplots()\n",
    "        # Just making it unitary for visualization purposes only.\n",
    "        b_tilde_2 = np.array([np.linalg.norm(b), 0])/np.linalg.norm(b)\n",
    "        # Just making it unitary for visualization purposes only.\n",
    "        h_tilde_1 = H[:2,0]/np.linalg.norm(H[:2,0])\n",
    "        ax.set_title(r'Small least-square problem for GMRes with $k=1$')\n",
    "        #######################################\n",
    "        Q_out = ax.quiver(0, 0, b_tilde_2[0], b_tilde_2[1], angles='xy', scale_units='xy', scale=1, units='x',color='green')\n",
    "        ax.quiverkey(Q_out, b_tilde_2[0], b_tilde_2[1], 0, r'$\\widetilde{\\mathbf{b}}_2$',coordinates='data')\n",
    "        #######################################\n",
    "        Q_out = ax.quiver(0, 0, h_tilde_1[0], h_tilde_1[1], angles='xy', scale_units='xy', scale=1, units='xy', color='blue', alpha=0.5)\n",
    "        ax.quiverkey(Q_out, h_tilde_1[0], h_tilde_1[1], 0, r'$\\widetilde{\\mathbf{h}}_1$',coordinates='data',labelpos='E')\n",
    "        #######################################\n",
    "        plt.grid(True)\n",
    "        ax.set_xlim([-1.5,1.5])\n",
    "        ax.set_ylim([-1.5,1.5])\n",
    "        plt.show()\n",
    "    elif k>1:\n",
    "        ax = plt.figure().add_subplot(projection='3d')\n",
    "        \n",
    "        # Just making it unitary for visualization purposes only.\n",
    "        b_tilde_3 = np.array([np.linalg.norm(b), 0, 0])/np.linalg.norm(b)\n",
    "        # Just making it unitary for visualization purposes only.\n",
    "        h_1 = H[:,0]/np.linalg.norm(H[:,0])\n",
    "        h_2 = H[:,1]/np.linalg.norm(H[:,1])\n",
    "        h_3 = H[:,2]/np.linalg.norm(H[:,2])\n",
    "        \n",
    "        ax.quiver(0, 0, 0, h_1[0], h_1[1], h_1[2], length=1, normalize=True,color='blue',alpha=0.5)\n",
    "        ax.text(h_1[0], h_1[1], h_1[2], r'$\\mathbf{h}_1$',(1,1,0))\n",
    "        ax.quiver(0, 0, 0, h_2[0], h_2[1], h_2[2], length=1, normalize=True,color='blue',alpha=0.5)\n",
    "        ax.text(h_2[0], h_2[1], h_2[2], r'$\\mathbf{h}_2$',(1,1,0))\n",
    "        if k==3:\n",
    "            ax.quiver(0, 0, 0, h_3[0], h_3[1], h_3[2], length=1, normalize=True,color='blue',alpha=0.5)\n",
    "            ax.text(h_3[0], h_3[1], h_3[2], r'$\\mathbf{h}_3$',(1,1,0))\n",
    "        \n",
    "        ax.quiver(0, 0, 0, b_tilde_3[0], b_tilde_3[1], b_tilde_3[2], color='green',alpha=0.5)\n",
    "        ax.text(b_tilde_3[0], b_tilde_3[1], b_tilde_3[2], r'$\\mathbf{b}$',(1,1,0))\n",
    "        \n",
    "        ax.view_init(elev, azim, roll)\n",
    "        ax.set_xlabel(r'$x_1$')\n",
    "        ax.set_ylabel(r'$x_2$')\n",
    "        ax.set_zlabel(r'$x_3$')\n",
    "        ax.set_xlim(-1, 1)\n",
    "        ax.set_ylim(-1, 1)\n",
    "        ax.set_zlim(-1, 1)\n",
    "        \n",
    "        if k==2:\n",
    "            plt.title(r'Small least-square problem for GMRes with $k=2$')\n",
    "        else:\n",
    "            plt.title(r'Small least-square problem for GMRes with $k=3$')\n",
    "            \n",
    "        plt.show()\n",
    "    \n",
    "interact(show_vectors3,elev=(0,360,1),azim=(0,360,1),roll=(0,360,1),k=(1,3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='colorfulgmres' />\n",
    "\n",
    "# Colorful version of GMRes\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "This implementation fo GMRes show the computation step by step.\n",
    "The first cell defines the problem to be solve and the next cell executes GMRes.\n",
    "For clarity, we show here the 4 matrices we will use as examples:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    A_0 &= \\begin{bmatrix}\n",
    "            1 & 2 & 3\\\\\n",
    "            3 & 2 & 1\\\\\n",
    "            1 & 1 & -1\n",
    "        \\end{bmatrix},\\\\\n",
    "    A_1 &= \\mathrm{Random\\; matrix},\\\\\n",
    "    A_2 &= \\begin{bmatrix}\n",
    "            1 & 0 & 2\\\\\n",
    "            0 & 1 & 3\\\\\n",
    "            0 & 0 & 1\n",
    "        \\end{bmatrix},\\\\\n",
    "    A_3 &= \\begin{bmatrix}\n",
    "            2 & 0 & 0\\\\\n",
    "            0 & 2 & 0\\\\\n",
    "            0 & 0 & 2\n",
    "        \\end{bmatrix}.\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the 'seed' of the random number generator to obtain reproducible outcomes.\n",
    "rng = np.random.Generator(np.random.PCG64(seed=0))\n",
    "threshold = 1e-12\n",
    "\n",
    "# Defining size of the matrix\n",
    "n = 3\n",
    "# Defining number of iterations.\n",
    "# For m=n, we need to change a little bit the main loop\n",
    "m = 3\n",
    "# Building a random matrix\n",
    "A1 = rng.normal(0,1,size=(n,n))\n",
    "b = np.ones(n)\n",
    "\n",
    "###########################################################################\n",
    "# Original matrix\n",
    "A0 = np.array([[1,2,3],[3,2,1],[1,1,-1]])\n",
    "###########################################################################\n",
    "A2 = np.array([[1,0,2],[0,1,3],[0,0,1]])\n",
    "###########################################################################\n",
    "A3 = np.eye(3)*2\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='ma0' />\n",
    "\n",
    "## Matrix $A_0$\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "$$\n",
    "A_0 = \\begin{bmatrix}\n",
    "            1 & 2 & 3\\\\\n",
    "            3 & 2 & 1\\\\\n",
    "            1 & 1 & -1\n",
    "        \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[42m\u001b[30mProcessing column \u001b[0m \u001b[1mk =\u001b[0m \u001b[1m0\u001b[0m\n",
      "  \u001b[1m\u001b[43mReduced problem solved:\u001b[0m\n",
      "   \u001b[1mH_tilde :\n",
      "\u001b[0m [[4.33333333]\n",
      " [2.3570226 ]]\n",
      "   \u001b[1m||b||*e_1 :\u001b[0m [1.73205081 0.        ]\n",
      "   \u001b[1mck:\u001b[0m [0.3084474]\n",
      "   \u001b[1m\u001b[43m||nb*e1-H_tilde@ck||\t=\u001b[0m 0.8276058886023681\n",
      "   \u001b[1mxk found:\u001b[0m [0.17808219 0.17808219 0.17808219]\n",
      "   \u001b[1m\u001b[43m||b-A@xk||\t\t=\u001b[0m 0.8276058886023681\n",
      "\u001b[1m\u001b[42m\u001b[30mProcessing column \u001b[0m \u001b[1mk =\u001b[0m \u001b[1m1\u001b[0m\n",
      "  \u001b[1m\u001b[43mReduced problem solved:\u001b[0m\n",
      "   \u001b[1mH_tilde :\n",
      "\u001b[0m [[ 4.33333333  0.94280904]\n",
      " [ 2.3570226  -1.33333333]\n",
      " [ 0.          1.73205081]]\n",
      "   \u001b[1m||b||*e_1 :\u001b[0m [1.73205081 0.         0.        ]\n",
      "   \u001b[1mck:\u001b[0m [0.29921072 0.23839316]\n",
      "   \u001b[1m\u001b[43m||nb*e1-H_tilde@ck||\t=\u001b[0m 0.6041220933301769\n",
      "   \u001b[1mxk found:\u001b[0m [ 0.27007299  0.27007299 -0.02189781]\n",
      "   \u001b[1m\u001b[43m||b-A@xk||\t\t=\u001b[0m 0.6041220933301769\n",
      "\u001b[1m\u001b[42m\u001b[30mProcessing column \u001b[0m \u001b[1mk =\u001b[0m \u001b[1m2\u001b[0m\n",
      "  \u001b[1m\u001b[43mReduced problem solved:\u001b[0m\n",
      "   \u001b[1mH_tilde :\n",
      "\u001b[0m [[ 4.33333333e+00  9.42809042e-01 -1.66267752e-15]\n",
      " [ 2.35702260e+00 -1.33333333e+00 -7.41564343e-16]\n",
      " [ 0.00000000e+00  1.73205081e+00 -1.00000000e+00]]\n",
      "   \u001b[1m||b||*e_1 :\u001b[0m [1.73205081 0.         0.        ]\n",
      "   \u001b[1mck:\u001b[0m [0.28867513 0.51031036 0.88388348]\n",
      "   \u001b[1m\u001b[43m||nb*e1-H_tilde@ck||\t=\u001b[0m 3.296615288236015e-16\n",
      "   \u001b[1mxk found:\u001b[0m [-0.25  1.   -0.25]\n",
      "   \u001b[1m\u001b[43m||b-A@xk||\t\t=\u001b[0m 3.296615288236015e-16\n",
      "\u001b[1m\u001b[41m\u001b[30m####################################################################################\u001b[0m\n",
      "\u001b[1m\u001b[42m\u001b[30mGMRes finished in \u001b[0m \u001b[1m3\u001b[0m \u001b[1m\u001b[42m\u001b[30miterations.\u001b[0m\n",
      "\u001b[1m\u001b[41m\u001b[30m####################################################################################\u001b[0m\n",
      "\u001b[1m\u001b[43m\n",
      "GMRes approximation\t:\u001b[0m [-0.25  1.   -0.25]\n",
      "\u001b[1m\u001b[43mnp.linalg.solve\t\t:\u001b[0m [-0.25  1.   -0.25]\n"
     ]
    }
   ],
   "source": [
    "colorful_GMRes(A0,b,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='ma1' />\n",
    "\n",
    "## Matrix $A_1$\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "$$\n",
    "A_1 = \\mathrm{Random\\; matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[42m\u001b[30mProcessing column \u001b[0m \u001b[1mk =\u001b[0m \u001b[1m0\u001b[0m\n",
      "  \u001b[1m\u001b[43mReduced problem solved:\u001b[0m\n",
      "   \u001b[1mH_tilde :\n",
      "\u001b[0m [[0.70407319]\n",
      " [0.66179647]]\n",
      "   \u001b[1m||b||*e_1 :\u001b[0m [1.73205081 0.        ]\n",
      "   \u001b[1mck:\u001b[0m [1.30609282]\n",
      "   \u001b[1m\u001b[43m||nb*e1-H_tilde@ck||\t=\u001b[0m 1.186268165392827\n",
      "   \u001b[1mxk found:\u001b[0m [0.75407304 0.75407304 0.75407304]\n",
      "   \u001b[1m\u001b[43m||b-A@xk||\t\t=\u001b[0m 1.186268165392827\n",
      "\u001b[1m\u001b[42m\u001b[30mProcessing column \u001b[0m \u001b[1mk =\u001b[0m \u001b[1m1\u001b[0m\n",
      "  \u001b[1m\u001b[43mReduced problem solved:\u001b[0m\n",
      "   \u001b[1mH_tilde :\n",
      "\u001b[0m [[ 0.70407319 -0.03621584]\n",
      " [ 0.66179647 -1.36212133]\n",
      " [ 0.          0.60214518]]\n",
      "   \u001b[1m||b||*e_1 :\u001b[0m [1.73205081 0.         0.        ]\n",
      "   \u001b[1mck:\u001b[0m [2.18341144 0.88370529]\n",
      "   \u001b[1m\u001b[43m||nb*e1-H_tilde@ck||\t=\u001b[0m 0.6267241610367571\n",
      "   \u001b[1mxk found:\u001b[0m [1.20660774 0.66446337 1.91070844]\n",
      "   \u001b[1m\u001b[43m||b-A@xk||\t\t=\u001b[0m 0.6267241610367571\n",
      "\u001b[1m\u001b[42m\u001b[30mProcessing column \u001b[0m \u001b[1mk =\u001b[0m \u001b[1m2\u001b[0m\n",
      "  \u001b[1m\u001b[43mReduced problem solved:\u001b[0m\n",
      "   \u001b[1mH_tilde :\n",
      "\u001b[0m [[ 0.70407319 -0.03621584  0.58622611]\n",
      " [ 0.66179647 -1.36212133  0.51039643]\n",
      " [ 0.          0.60214518 -0.45562625]]\n",
      "   \u001b[1m||b||*e_1 :\u001b[0m [1.73205081 0.         0.        ]\n",
      "   \u001b[1mck:\u001b[0m [1.22415698 1.17822986 1.55712151]\n",
      "   \u001b[1m\u001b[43m||nb*e1-H_tilde@ck||\t=\u001b[0m 3.1401849173675503e-16\n",
      "   \u001b[1mxk found:\u001b[0m [ 1.90261027 -0.80433332  1.02202514]\n",
      "   \u001b[1m\u001b[43m||b-A@xk||\t\t=\u001b[0m 3.1401849173675503e-16\n",
      "\u001b[1m\u001b[41m\u001b[30m####################################################################################\u001b[0m\n",
      "\u001b[1m\u001b[42m\u001b[30mGMRes finished in \u001b[0m \u001b[1m3\u001b[0m \u001b[1m\u001b[42m\u001b[30miterations.\u001b[0m\n",
      "\u001b[1m\u001b[41m\u001b[30m####################################################################################\u001b[0m\n",
      "\u001b[1m\u001b[43m\n",
      "GMRes approximation\t:\u001b[0m [ 1.90261027 -0.80433332  1.02202514]\n",
      "\u001b[1m\u001b[43mnp.linalg.solve\t\t:\u001b[0m [ 1.90261027 -0.80433332  1.02202514]\n"
     ]
    }
   ],
   "source": [
    "colorful_GMRes(A1,b,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='ma2' />\n",
    "\n",
    "## Matrix $A_2$\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "$$\n",
    "A_2 = \\begin{bmatrix}\n",
    "            1 & 0 & 2\\\\\n",
    "            0 & 1 & 3\\\\\n",
    "            0 & 0 & 1\n",
    "        \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[42m\u001b[30mProcessing column \u001b[0m \u001b[1mk =\u001b[0m \u001b[1m0\u001b[0m\n",
      "  \u001b[1m\u001b[43mReduced problem solved:\u001b[0m\n",
      "   \u001b[1mH_tilde :\n",
      "\u001b[0m [[2.66666667]\n",
      " [1.24721913]]\n",
      "   \u001b[1m||b||*e_1 :\u001b[0m [1.73205081 0.        ]\n",
      "   \u001b[1mck:\u001b[0m [0.53293871]\n",
      "   \u001b[1m\u001b[43m||nb*e1-H_tilde@ck||\t=\u001b[0m 0.7337993857053426\n",
      "   \u001b[1mxk found:\u001b[0m [0.30769231 0.30769231 0.30769231]\n",
      "   \u001b[1m\u001b[43m||b-A@xk||\t\t=\u001b[0m 0.7337993857053426\n",
      "\u001b[1m\u001b[42m\u001b[30mProcessing column \u001b[0m \u001b[1mk =\u001b[0m \u001b[1m1\u001b[0m\n",
      "  \u001b[1m\u001b[43mReduced problem solved:\u001b[0m\n",
      "   \u001b[1mH_tilde :\n",
      "\u001b[0m [[ 2.66666667 -2.22717702]\n",
      " [ 1.24721913 -0.66666667]]\n",
      "   \u001b[1m||b||*e_1 :\u001b[0m [1.73205081 0.        ]\n",
      "   \u001b[1mck:\u001b[0m [-1.15470054 -2.1602469 ]\n",
      "   \u001b[1m\u001b[43m||nb*e1-H_tilde@ck||\t=\u001b[0m 4.440892098500626e-16\n",
      "   \u001b[1mxk found:\u001b[0m [-1. -2.  1.]\n",
      "   \u001b[1m\u001b[43m||b-A@xk||\t\t=\u001b[0m 4.440892098500626e-16\n",
      "\u001b[1m\u001b[41m\u001b[30m####################################################################################\u001b[0m\n",
      "\u001b[1m\u001b[42m\u001b[30mGMRes finished in only \u001b[0m \u001b[1m2\u001b[0m \u001b[1m\u001b[42m\u001b[30miterations!!!\u001b[0m\n",
      "\u001b[1m\u001b[41m\u001b[30m####################################################################################\u001b[0m\n",
      "\u001b[1m\u001b[43m\n",
      "GMRes approximation\t:\u001b[0m [-1. -2.  1.]\n",
      "\u001b[1m\u001b[43mnp.linalg.solve\t\t:\u001b[0m [-1. -2.  1.]\n"
     ]
    }
   ],
   "source": [
    "colorful_GMRes(A2,b,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='ma3' />\n",
    "\n",
    "## Matrix $A_3$\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "$$\n",
    "A_3 = \\begin{bmatrix}\n",
    "            2 & 0 & 0\\\\\n",
    "            0 & 2 & 0\\\\\n",
    "            0 & 0 & 2\n",
    "        \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[42m\u001b[30mProcessing column \u001b[0m \u001b[1mk =\u001b[0m \u001b[1m0\u001b[0m\n",
      "  \u001b[1m\u001b[43mReduced problem solved:\u001b[0m\n",
      "   \u001b[1mH_tilde :\n",
      "\u001b[0m [[2.]]\n",
      "   \u001b[1m||b||*e_1 :\u001b[0m [1.73205081]\n",
      "   \u001b[1mck:\u001b[0m [0.8660254]\n",
      "   \u001b[1m\u001b[43m||nb*e1-H_tilde@ck||\t=\u001b[0m 0.0\n",
      "   \u001b[1mxk found:\u001b[0m [0.5 0.5 0.5]\n",
      "   \u001b[1m\u001b[43m||b-A@xk||\t\t=\u001b[0m 0.0\n",
      "\u001b[1m\u001b[41m\u001b[30m####################################################################################\u001b[0m\n",
      "\u001b[1m\u001b[42m\u001b[30mGMRes finished in only \u001b[0m \u001b[1m1\u001b[0m \u001b[1m\u001b[42m\u001b[30miterations!!!\u001b[0m\n",
      "\u001b[1m\u001b[41m\u001b[30m####################################################################################\u001b[0m\n",
      "\u001b[1m\u001b[43m\n",
      "GMRes approximation\t:\u001b[0m [0.5 0.5 0.5]\n",
      "\u001b[1m\u001b[43mnp.linalg.solve\t\t:\u001b[0m [0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "colorful_GMRes(A3,b,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='uncolorfulgmres' />\n",
    "\n",
    "## With a widget but lossing the colors..., nevertheless it is useful for looking at different values of $m$\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb9c29ea8d64114bf134f16c07ea07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Matrix:', options=(('A0', 0), ('A1', 1), ('A2', 2), ('A3', 3)), va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(i)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrices=(A0,A1,A2,A3)\n",
    "matrix_widget = widgets.Dropdown(\n",
    "    options=[('A0',0),('A1',1),('A2',2),('A3',3)],\n",
    "    value=0,\n",
    "    description='Matrix:',\n",
    ")\n",
    "\n",
    "interact(lambda i: colorful_GMRes(Matrices[i],b,m), i=matrix_widget, m=(1,3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='acknowledgements' />\n",
    "\n",
    "# Acknowledgements\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "* _Material created by professor Claudio Torres_ (`ctorres@inf.utfsm.cl` and `claudio.torres@usm.cl`). _DI UTFSM. June 2024._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
